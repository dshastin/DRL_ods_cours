{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Домашнее задание 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Исследуем алгоритм Кросс-Энтропии с использованием нейронных сетей."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Warning: Gym version v0.24.0 has a number of critical issues with `gym.make` such that the `reset` and `step` functions are called before returning the environment. It is recommend to downgrading to v0.23.1 or upgrading to v0.25.1\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from torch import nn \n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import gym\n",
    "import plotly.express as px\n",
    "import time\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CEM(nn.Module):\n",
    "    def __init__(self, state_dim, action_n, hidden, lr=0.01, eps=0):\n",
    "        super().__init__()\n",
    "        self.state_dim = state_dim\n",
    "        self.action_n = action_n\n",
    "        self.lr = lr\n",
    "        self.eps = eps\n",
    "\n",
    "        self.network = nn.Sequential(\n",
    "            nn.Linear(self.state_dim, hidden),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(hidden, action_n)\n",
    "        )\n",
    "        \n",
    "        self.softmax = nn.Softmax(dim=0)\n",
    "        self.optimizer = torch.optim.Adam(self.parameters(), lr=lr)\n",
    "        self.loss = nn.CrossEntropyLoss()\n",
    "        \n",
    "    def forward(self, _input):\n",
    "        return self.network(_input) \n",
    "    \n",
    "    def get_action(self, state):\n",
    "        state = torch.FloatTensor(state)\n",
    "        logits = self.forward(state)\n",
    "        action_prob = self.softmax(logits).detach().numpy()\n",
    "\n",
    "        noise = np.ones(self.action_n) / self.action_n\n",
    "        action_prob_noised = (1 - self.eps) * action_prob + self.eps * noise\n",
    "        action_prob_noised = action_prob_noised / np.sum(action_prob_noised)\n",
    "        action = np.random.choice(self.action_n, p=action_prob_noised)\n",
    "        return action\n",
    "    \n",
    "    def update_policy(self, elite_states, elite_actions):\n",
    "        elite_states_tensor = torch.FloatTensor(elite_states)\n",
    "        elite_actions_tensor = torch.LongTensor(elite_actions)\n",
    "\n",
    "        loss = self.loss(self.forward(elite_states_tensor), elite_actions_tensor)\n",
    "        loss.backward()\n",
    "        self.optimizer.step()\n",
    "        self.optimizer.zero_grad()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_trajectory(env, agent, trajectory_len, visualize=False):\n",
    "    trajectory = {'states':[], 'actions': [], 'total_reward': 0}\n",
    "    \n",
    "    state = env.reset()\n",
    "    trajectory['states'].append(state)\n",
    "    \n",
    "    for _ in range(trajectory_len):\n",
    "        action = agent.get_action(state)\n",
    "        trajectory['actions'].append(action)\n",
    "        \n",
    "        state, reward, done, _ = env.step(action)\n",
    "        trajectory['total_reward'] += reward\n",
    "        \n",
    "        if done:\n",
    "            break\n",
    "    \n",
    "        if visualize:\n",
    "            env.render()\n",
    "            \n",
    "        trajectory['states'].append(state)\n",
    "    return trajectory\n",
    "\n",
    "def get_elite_trajectories(trajectories, q_param):\n",
    "    total_rewards = [trajectory['total_reward'] for trajectory in trajectories]\n",
    "    quantile = np.quantile(total_rewards, q=q_param) \n",
    "    return [trajectory for trajectory in trajectories if trajectory['total_reward'] > quantile]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_batch(env, agent, batch_size, trajectory_len):\n",
    "    batch_states, batch_actions, batch_rewards = [], [], []\n",
    "\n",
    "    for _ in range(batch_size):\n",
    "        states, actions = [], []\n",
    "        total_reward = 0\n",
    "\n",
    "        state = env.reset()\n",
    "        for _ in range(trajectory_len):\n",
    "            action = agent.get_action(state)\n",
    "            new_state, reward, done, _ = env.step(action)\n",
    "            states.append(state)\n",
    "            actions.append(action)\n",
    "            total_reward += reward\n",
    "            state = new_state\n",
    "            \n",
    "            if done:\n",
    "                batch_actions.append(actions)\n",
    "                batch_states.append(states)\n",
    "                batch_rewards.append(total_reward)\n",
    "                break\n",
    "    return batch_states, batch_actions, batch_rewards"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_elite_states(batch_states, batch_actions, batch_rewards, q_param):\n",
    "    quantile = np.quantile(batch_rewards, q=q_param) \n",
    "\n",
    "    elite_states = []\n",
    "    elite_actions = []\n",
    "    for i in range(len(batch_rewards)):\n",
    "        if batch_rewards[i] > quantile:\n",
    "            for j in range(len(batch_states[i])):\n",
    "                elite_states.append(batch_states[i][j])\n",
    "                elite_actions.append(batch_actions[i][j])\n",
    "    \n",
    "    return elite_states, elite_actions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "env = gym.make(\n",
    "    \"LunarLander-v2\",\n",
    "    continuous = False,\n",
    "    gravity = -10.0,\n",
    "    enable_wind = False,\n",
    "    wind_power = 15.0,\n",
    "    turbulence_power = 1.5)\n",
    "\n",
    "state_dim = 8\n",
    "action_n = 4\n",
    "lr = 1e-2\n",
    "eps = 0\n",
    "\n",
    "trajectory_n = 500\n",
    "\n",
    "MAX_ITER = 300\n",
    "BATCH_SIZE = 50\n",
    "TRAJECTORY_LEN = 1000\n",
    "Q = 0.75"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Пробуем однослойную полносвязную архитектуру с разным количество слоев.\n",
    "Гиперпараметры пока оставляю фиксированные, показавшиеся наиболее оптимальными на предыдущих запусках."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "total_rewards = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\denis\\AppData\\Local\\Temp\\ipykernel_27608\\1864093162.py:34: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at ..\\torch\\csrc\\utils\\tensor_new.cpp:264.)\n",
      "  elite_states_tensor = torch.FloatTensor(elite_states)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0: mean_reward=-191.48395824124694\n",
      "1: mean_reward=-174.2419655171212\n",
      "2: mean_reward=-208.92693535157505\n",
      "3: mean_reward=-205.46261584454933\n",
      "4: mean_reward=-189.12988426996998\n",
      "5: mean_reward=-177.145662975239\n",
      "6: mean_reward=-163.50331161796714\n",
      "7: mean_reward=-173.64757818948314\n",
      "8: mean_reward=-180.31325101368782\n",
      "9: mean_reward=-175.11206418323044\n",
      "10: mean_reward=-165.17564633666848\n",
      "11: mean_reward=-191.588429659361\n",
      "12: mean_reward=-172.04514112870672\n",
      "13: mean_reward=-166.550656179244\n",
      "14: mean_reward=-149.70976027911104\n",
      "15: mean_reward=-156.3929513224928\n",
      "16: mean_reward=-174.412732258016\n",
      "17: mean_reward=-148.71432268954584\n",
      "18: mean_reward=-170.89355312810065\n",
      "19: mean_reward=-140.32884151437483\n",
      "20: mean_reward=-166.3467893099404\n",
      "21: mean_reward=-160.83282092929824\n",
      "22: mean_reward=-149.57180365839602\n",
      "23: mean_reward=-147.77366404994933\n",
      "24: mean_reward=-147.50249041027158\n",
      "25: mean_reward=-149.52373063988506\n",
      "26: mean_reward=-150.93125737988822\n",
      "27: mean_reward=-136.11214449074043\n",
      "28: mean_reward=-150.01022350988612\n",
      "29: mean_reward=-131.64334625940097\n",
      "30: mean_reward=-160.46679343842663\n",
      "31: mean_reward=-134.46226844423595\n",
      "32: mean_reward=-140.5845685018228\n",
      "33: mean_reward=-133.113411361467\n",
      "34: mean_reward=-137.4436148863879\n",
      "35: mean_reward=-145.8258655532491\n",
      "36: mean_reward=-159.52866902818153\n",
      "37: mean_reward=-136.65099028706686\n",
      "38: mean_reward=-127.57253130968333\n",
      "39: mean_reward=-134.29273250574647\n",
      "40: mean_reward=-136.03672168868397\n",
      "41: mean_reward=-140.14052866448833\n",
      "42: mean_reward=-125.4890346064967\n",
      "43: mean_reward=-126.5207144947114\n",
      "44: mean_reward=-133.15765485762438\n",
      "45: mean_reward=-142.7267167833463\n",
      "46: mean_reward=-139.6806414030879\n",
      "47: mean_reward=-128.83206838011654\n",
      "48: mean_reward=-113.74009682220147\n",
      "49: mean_reward=-113.46172987384666\n",
      "50: mean_reward=-108.28317000328923\n",
      "51: mean_reward=-114.37313744029382\n",
      "52: mean_reward=-106.38155525690563\n",
      "53: mean_reward=-114.48312547412884\n",
      "54: mean_reward=-121.86385543278811\n",
      "55: mean_reward=-106.20327065977266\n",
      "56: mean_reward=-101.4428667328588\n",
      "57: mean_reward=-99.66222898679392\n",
      "58: mean_reward=-89.56847167599831\n",
      "59: mean_reward=-103.15090774620599\n",
      "60: mean_reward=-102.71377918920473\n",
      "61: mean_reward=-100.60738593235685\n",
      "62: mean_reward=-98.3424238446244\n",
      "63: mean_reward=-82.9747717428105\n",
      "64: mean_reward=-87.30679880498423\n",
      "65: mean_reward=-86.75966028779372\n",
      "66: mean_reward=-78.5155873073602\n",
      "67: mean_reward=-82.16431985852141\n",
      "68: mean_reward=-80.07883726946012\n",
      "69: mean_reward=-68.13559841512038\n",
      "70: mean_reward=-67.98038870430331\n",
      "71: mean_reward=-69.9029145691322\n",
      "72: mean_reward=-80.83450666254966\n",
      "73: mean_reward=-73.93851730416173\n",
      "74: mean_reward=-71.59019820292839\n",
      "75: mean_reward=-70.24430752705464\n",
      "76: mean_reward=-69.39465455217952\n",
      "77: mean_reward=-68.58985825874544\n",
      "78: mean_reward=-65.577196234761\n",
      "79: mean_reward=-88.18172609958587\n",
      "80: mean_reward=-87.51982656874597\n",
      "81: mean_reward=-96.49386799718394\n",
      "82: mean_reward=-100.0382950841626\n",
      "83: mean_reward=-96.13715812560186\n",
      "84: mean_reward=-121.57028762174872\n",
      "85: mean_reward=-127.84776265294242\n",
      "86: mean_reward=-83.947639208687\n",
      "87: mean_reward=-53.40416201852772\n",
      "88: mean_reward=-62.720491098916234\n",
      "89: mean_reward=-54.76961715353745\n",
      "90: mean_reward=-39.33442438919733\n",
      "91: mean_reward=-50.46840710604414\n",
      "92: mean_reward=-29.48126526529115\n",
      "93: mean_reward=-28.82051456550058\n",
      "94: mean_reward=-25.705225454842584\n",
      "95: mean_reward=-28.82179548748643\n",
      "96: mean_reward=-32.593683323589595\n",
      "97: mean_reward=-33.282161830512536\n",
      "98: mean_reward=-25.774719834440603\n",
      "99: mean_reward=-34.78881777186409\n",
      "100: mean_reward=-31.39798227181042\n",
      "101: mean_reward=-30.518425946671915\n",
      "102: mean_reward=-17.685519203106015\n",
      "103: mean_reward=-25.34374499176195\n",
      "104: mean_reward=-23.91580058826111\n",
      "105: mean_reward=-11.111352600941286\n",
      "106: mean_reward=-7.843867714473885\n",
      "107: mean_reward=-30.25952843416491\n",
      "108: mean_reward=-12.753268503814429\n",
      "109: mean_reward=-25.081305527982593\n",
      "110: mean_reward=-21.865988643803806\n",
      "111: mean_reward=-17.049191313652333\n",
      "112: mean_reward=-23.597800921725256\n",
      "113: mean_reward=-33.95538952464531\n",
      "114: mean_reward=-10.879999154169191\n",
      "115: mean_reward=-35.865067816296225\n",
      "116: mean_reward=-35.14494884125753\n",
      "117: mean_reward=-28.786639150310066\n",
      "118: mean_reward=-26.88193585589733\n",
      "119: mean_reward=-20.940035621228375\n",
      "120: mean_reward=-66.69271908634876\n",
      "121: mean_reward=-36.272125096622084\n",
      "122: mean_reward=-17.035632098868767\n",
      "123: mean_reward=-17.98692035881015\n",
      "124: mean_reward=8.807671480612619\n",
      "125: mean_reward=-1.8948380738902835\n",
      "126: mean_reward=-2.562068739692898\n",
      "127: mean_reward=3.127878971481144\n",
      "128: mean_reward=-22.981213901321823\n",
      "129: mean_reward=-13.141905048262135\n",
      "130: mean_reward=-7.317701948313264\n",
      "131: mean_reward=1.2930298016068473\n",
      "132: mean_reward=-1.8523804515429811\n",
      "133: mean_reward=-0.2511646132291679\n",
      "134: mean_reward=-3.73332386238066\n",
      "135: mean_reward=0.704332384706239\n",
      "136: mean_reward=-0.015760317898549373\n",
      "137: mean_reward=10.503069989447129\n",
      "138: mean_reward=3.4693729782912577\n",
      "139: mean_reward=7.550792085004187\n",
      "140: mean_reward=0.9771266033635112\n",
      "141: mean_reward=5.4236147248777025\n",
      "142: mean_reward=2.7832608366808307\n",
      "143: mean_reward=7.516513075223603\n",
      "144: mean_reward=5.18824238463298\n",
      "145: mean_reward=1.3582244826275962\n",
      "146: mean_reward=11.364489990491435\n",
      "147: mean_reward=-2.0159247585320634\n",
      "148: mean_reward=3.8716048633147455\n",
      "149: mean_reward=8.110069713233493\n",
      "150: mean_reward=9.974392679239614\n",
      "151: mean_reward=1.2840782501684231\n",
      "152: mean_reward=18.549733739623694\n",
      "153: mean_reward=8.737357642606726\n",
      "154: mean_reward=5.733940816098129\n",
      "155: mean_reward=9.58813531938529\n",
      "156: mean_reward=7.8008903035826345\n",
      "157: mean_reward=16.881169415761995\n",
      "158: mean_reward=9.518189783247898\n",
      "159: mean_reward=29.313608342349816\n",
      "160: mean_reward=0.9110550789168101\n",
      "161: mean_reward=28.715895229089462\n",
      "162: mean_reward=14.51227513914978\n",
      "163: mean_reward=13.698932616241922\n",
      "164: mean_reward=10.601869512911156\n",
      "165: mean_reward=8.936817428604515\n",
      "166: mean_reward=9.917099169117025\n",
      "167: mean_reward=7.06568350078069\n",
      "168: mean_reward=-8.561953019685967\n",
      "169: mean_reward=25.83458387278872\n",
      "170: mean_reward=20.716133065420475\n",
      "171: mean_reward=18.19683473064717\n",
      "172: mean_reward=11.139230089476737\n",
      "173: mean_reward=1.0537440722564981\n",
      "174: mean_reward=29.640456143148754\n",
      "175: mean_reward=7.756538626727352\n",
      "176: mean_reward=19.886234611173577\n",
      "177: mean_reward=4.6301969501348506\n",
      "178: mean_reward=3.940023873681913\n",
      "179: mean_reward=17.663151890124954\n",
      "180: mean_reward=27.35883102648985\n",
      "181: mean_reward=1.9864664123298925\n",
      "182: mean_reward=11.0022854623214\n",
      "183: mean_reward=12.566493291129234\n",
      "184: mean_reward=31.187999403090316\n",
      "185: mean_reward=17.41556480720402\n",
      "186: mean_reward=32.65472889053723\n",
      "187: mean_reward=15.853350551971925\n",
      "188: mean_reward=4.817504218281395\n",
      "189: mean_reward=21.77804858129735\n",
      "190: mean_reward=22.525059007041037\n",
      "191: mean_reward=24.15251710424244\n",
      "192: mean_reward=6.11013048181234\n",
      "193: mean_reward=2.9469858625268524\n",
      "194: mean_reward=19.01276980700567\n",
      "195: mean_reward=12.823131197625864\n",
      "196: mean_reward=15.386956419848136\n",
      "197: mean_reward=34.2878907563467\n",
      "198: mean_reward=8.192453699804185\n",
      "199: mean_reward=47.1483493960018\n",
      "200: mean_reward=30.466564653374782\n",
      "201: mean_reward=34.39981619759888\n",
      "202: mean_reward=13.609141072825537\n",
      "203: mean_reward=24.144627350257107\n",
      "204: mean_reward=15.203683689458307\n",
      "205: mean_reward=6.735947665758631\n",
      "206: mean_reward=11.845531573101516\n",
      "207: mean_reward=22.989628641068304\n",
      "208: mean_reward=12.487632905243402\n",
      "209: mean_reward=26.83634132583146\n",
      "210: mean_reward=30.4295497676832\n",
      "211: mean_reward=45.61442542380512\n",
      "212: mean_reward=25.149897470414086\n",
      "213: mean_reward=28.63055675490099\n",
      "214: mean_reward=11.87016596332986\n",
      "215: mean_reward=3.2288667217968\n",
      "216: mean_reward=26.14242232047566\n",
      "217: mean_reward=28.061888516064492\n",
      "218: mean_reward=15.191295269875779\n",
      "219: mean_reward=29.996809969567394\n",
      "220: mean_reward=40.20246499657986\n",
      "221: mean_reward=33.96833407520448\n",
      "222: mean_reward=19.780456300768172\n",
      "223: mean_reward=31.417136966378163\n",
      "224: mean_reward=36.36323470462194\n",
      "225: mean_reward=44.19656439380611\n",
      "226: mean_reward=31.392350746583226\n",
      "227: mean_reward=31.14698465181083\n",
      "228: mean_reward=51.77685507451877\n",
      "229: mean_reward=35.054655004412126\n",
      "230: mean_reward=36.289815566303844\n",
      "231: mean_reward=19.746671537470178\n",
      "232: mean_reward=38.065853823677074\n",
      "233: mean_reward=28.799128347774946\n",
      "234: mean_reward=45.07792579651858\n",
      "235: mean_reward=44.722728771826496\n",
      "236: mean_reward=44.29433856620455\n",
      "237: mean_reward=38.414497421966594\n",
      "238: mean_reward=30.056434489287536\n",
      "239: mean_reward=49.584519845414746\n",
      "240: mean_reward=31.605342784770297\n",
      "241: mean_reward=40.795516383397604\n",
      "242: mean_reward=36.33707658740168\n",
      "243: mean_reward=23.506363476165888\n",
      "244: mean_reward=52.04034190232488\n",
      "245: mean_reward=41.99095566336272\n",
      "246: mean_reward=40.50225480395086\n",
      "247: mean_reward=47.43011770146478\n",
      "248: mean_reward=52.17944302514177\n",
      "249: mean_reward=53.51042987679976\n",
      "250: mean_reward=25.515750482943716\n",
      "251: mean_reward=39.80725760897113\n",
      "252: mean_reward=31.01699867059484\n",
      "253: mean_reward=27.01334622119042\n",
      "254: mean_reward=45.52736559467989\n",
      "255: mean_reward=16.56483027159445\n",
      "256: mean_reward=39.095184829634455\n",
      "257: mean_reward=39.31686602041005\n",
      "258: mean_reward=24.917721583814146\n",
      "259: mean_reward=45.70276882216525\n",
      "260: mean_reward=25.099014663419293\n",
      "261: mean_reward=51.14271598054213\n",
      "262: mean_reward=33.60534043065246\n",
      "263: mean_reward=29.55916674283266\n",
      "264: mean_reward=57.973387632058056\n",
      "265: mean_reward=43.71496988430089\n",
      "266: mean_reward=41.27014910539738\n",
      "267: mean_reward=6.617499611740201\n",
      "268: mean_reward=25.411448329270996\n",
      "269: mean_reward=18.98023043217309\n",
      "270: mean_reward=49.39374929418386\n",
      "271: mean_reward=40.76402548232863\n",
      "272: mean_reward=53.30916471449698\n",
      "273: mean_reward=65.64040034859055\n",
      "274: mean_reward=74.59536604716075\n",
      "275: mean_reward=60.95497886527809\n",
      "276: mean_reward=36.38704212180033\n",
      "277: mean_reward=29.052181532819223\n",
      "278: mean_reward=38.172928738784755\n",
      "279: mean_reward=52.20749549721881\n",
      "280: mean_reward=39.7358554482403\n",
      "281: mean_reward=64.20894985642494\n",
      "282: mean_reward=38.215187537623564\n",
      "283: mean_reward=31.957273902421797\n",
      "284: mean_reward=83.3442428996488\n",
      "285: mean_reward=58.5267947564619\n",
      "286: mean_reward=88.68334660841406\n",
      "287: mean_reward=70.29136948018099\n",
      "288: mean_reward=74.98229320773639\n",
      "289: mean_reward=51.70662403477471\n",
      "290: mean_reward=59.79763994074731\n",
      "291: mean_reward=80.90043650219191\n",
      "292: mean_reward=43.14782029196843\n",
      "293: mean_reward=63.8116140960104\n",
      "294: mean_reward=88.40721671973489\n",
      "295: mean_reward=60.700501828181935\n",
      "296: mean_reward=81.70004296782179\n",
      "297: mean_reward=78.02163536635342\n",
      "298: mean_reward=92.12215925082644\n",
      "299: mean_reward=82.99980557416237\n"
     ]
    }
   ],
   "source": [
    "agent = CEM(state_dim, action_n, hidden=16, lr=lr)\n",
    "\n",
    "for i in range(MAX_ITER):\n",
    "    batch_states, batch_actions, batch_rewards = generate_batch(env, agent, BATCH_SIZE, TRAJECTORY_LEN)\n",
    "    elite_states, elite_actions = get_elite_states(batch_states, batch_actions, batch_rewards, Q)\n",
    "    \n",
    "    mean_reward = np.mean(batch_rewards)\n",
    "    agent.update_policy(elite_states, elite_actions)\n",
    "    print(f'{i}: mean_reward={mean_reward}')\n",
    "    total_rewards.append({'agent': 'one_layer_16', 'epoch': i, 'reward': mean_reward})\n",
    "\n",
    "time_end = time.time()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0: mean_reward=-150.08397642617263\n",
      "1: mean_reward=-153.8781485057967\n",
      "2: mean_reward=-134.68879070115284\n",
      "3: mean_reward=-170.11063683273758\n",
      "4: mean_reward=-129.81758142493538\n",
      "5: mean_reward=-140.37314885070774\n",
      "6: mean_reward=-139.72323002504956\n",
      "7: mean_reward=-135.48878488520876\n",
      "8: mean_reward=-126.86427345735993\n",
      "9: mean_reward=-133.98498217638763\n",
      "10: mean_reward=-115.63781789412015\n",
      "11: mean_reward=-120.91872621527631\n",
      "12: mean_reward=-126.43047371608245\n",
      "13: mean_reward=-110.58195337311831\n",
      "14: mean_reward=-133.63219182848368\n",
      "15: mean_reward=-121.83627462981207\n",
      "16: mean_reward=-118.98237893094343\n",
      "17: mean_reward=-120.09562860469279\n",
      "18: mean_reward=-109.90294009616127\n",
      "19: mean_reward=-119.30867288377065\n",
      "20: mean_reward=-115.17798873414577\n",
      "21: mean_reward=-118.2156888908358\n",
      "22: mean_reward=-99.16318635243547\n",
      "23: mean_reward=-97.2033748049157\n",
      "24: mean_reward=-94.56923364631061\n",
      "25: mean_reward=-93.74715547046318\n",
      "26: mean_reward=-93.91762917475411\n",
      "27: mean_reward=-88.11654764737101\n",
      "28: mean_reward=-76.60250902218405\n",
      "29: mean_reward=-71.51362023250384\n",
      "30: mean_reward=-79.41982289278587\n",
      "31: mean_reward=-75.67304013920273\n",
      "32: mean_reward=-82.02836469922892\n",
      "33: mean_reward=-84.50145997035287\n",
      "34: mean_reward=-87.63809849713732\n",
      "35: mean_reward=-87.40967324731446\n",
      "36: mean_reward=-80.00141521767857\n",
      "37: mean_reward=-69.97076227694257\n",
      "38: mean_reward=-50.881232950465744\n",
      "39: mean_reward=-80.82609818939196\n",
      "40: mean_reward=-68.85046200786896\n",
      "41: mean_reward=-77.75173917499812\n",
      "42: mean_reward=-98.30522660685033\n",
      "43: mean_reward=-90.06135559732088\n",
      "44: mean_reward=-82.49725935818743\n",
      "45: mean_reward=-77.17284191118017\n",
      "46: mean_reward=-102.46679907299072\n",
      "47: mean_reward=-66.84664369536613\n",
      "48: mean_reward=-104.84079745197772\n",
      "49: mean_reward=-75.64076059188345\n",
      "50: mean_reward=-94.35945357487824\n",
      "51: mean_reward=-83.61271075812785\n",
      "52: mean_reward=-66.5405320213036\n",
      "53: mean_reward=-37.845080891515124\n",
      "54: mean_reward=-37.98859733567181\n",
      "55: mean_reward=-0.3206933525731121\n",
      "56: mean_reward=-6.322382867156105\n",
      "57: mean_reward=-6.907817664524148\n",
      "58: mean_reward=-0.16258589631108009\n",
      "59: mean_reward=-3.1639036050193226\n",
      "60: mean_reward=-0.5751866964930116\n",
      "61: mean_reward=-3.636236181942628\n",
      "62: mean_reward=0.6119624938452037\n",
      "63: mean_reward=8.502297257595004\n",
      "64: mean_reward=0.3218439535259279\n",
      "65: mean_reward=4.301574046316088\n",
      "66: mean_reward=10.532575800627855\n",
      "67: mean_reward=7.457865646052299\n",
      "68: mean_reward=7.204042946930567\n",
      "69: mean_reward=0.42375903232003453\n",
      "70: mean_reward=6.064804441395823\n",
      "71: mean_reward=7.344134522731315\n",
      "72: mean_reward=9.609175606370654\n",
      "73: mean_reward=7.435331783342779\n",
      "74: mean_reward=0.8140525723014775\n",
      "75: mean_reward=16.100868483861905\n",
      "76: mean_reward=17.411621704455165\n",
      "77: mean_reward=17.7361602558687\n",
      "78: mean_reward=14.736032290678331\n",
      "79: mean_reward=16.01372291919171\n",
      "80: mean_reward=14.444324657339342\n",
      "81: mean_reward=23.89847533096247\n",
      "82: mean_reward=16.69276557299888\n",
      "83: mean_reward=22.019613821946518\n",
      "84: mean_reward=27.106965985962088\n",
      "85: mean_reward=12.900205266042777\n",
      "86: mean_reward=5.929614493502052\n",
      "87: mean_reward=7.693551326044623\n",
      "88: mean_reward=10.628124627799417\n",
      "89: mean_reward=13.488065563536065\n",
      "90: mean_reward=-1.9412531094830654\n",
      "91: mean_reward=9.110574879764064\n",
      "92: mean_reward=5.400998174863286\n",
      "93: mean_reward=20.32696802764212\n",
      "94: mean_reward=16.584529600713758\n",
      "95: mean_reward=12.75386989277677\n",
      "96: mean_reward=20.138730783705988\n",
      "97: mean_reward=30.43808727877549\n",
      "98: mean_reward=23.09084035840794\n",
      "99: mean_reward=36.57686787244728\n",
      "100: mean_reward=36.32965893986125\n",
      "101: mean_reward=35.534874514996396\n",
      "102: mean_reward=40.3399429227545\n",
      "103: mean_reward=39.17214937677715\n",
      "104: mean_reward=34.78476129705128\n",
      "105: mean_reward=44.28381289668914\n",
      "106: mean_reward=38.335921455914516\n",
      "107: mean_reward=53.14719635770068\n",
      "108: mean_reward=43.87528735094407\n",
      "109: mean_reward=43.219524500323544\n",
      "110: mean_reward=49.361647157886935\n",
      "111: mean_reward=38.110904370324555\n",
      "112: mean_reward=45.00740906361967\n",
      "113: mean_reward=43.81904574192349\n",
      "114: mean_reward=46.792770191653005\n",
      "115: mean_reward=49.184766278308096\n",
      "116: mean_reward=37.20756746234209\n",
      "117: mean_reward=47.72191166342627\n",
      "118: mean_reward=41.271525293864435\n",
      "119: mean_reward=27.01347532883728\n",
      "120: mean_reward=41.25366111673461\n",
      "121: mean_reward=42.65852005816793\n",
      "122: mean_reward=48.270491729630464\n",
      "123: mean_reward=49.85862823360869\n",
      "124: mean_reward=49.19881907512676\n",
      "125: mean_reward=40.85203868105165\n",
      "126: mean_reward=32.56910324421293\n",
      "127: mean_reward=35.948871037540755\n",
      "128: mean_reward=61.311606933026795\n",
      "129: mean_reward=42.45945934369074\n",
      "130: mean_reward=51.90118107281102\n",
      "131: mean_reward=49.138011525303746\n",
      "132: mean_reward=48.159328899574014\n",
      "133: mean_reward=59.42954680692923\n",
      "134: mean_reward=66.20175432664855\n",
      "135: mean_reward=56.81329607625882\n",
      "136: mean_reward=61.262030544652944\n",
      "137: mean_reward=67.0776006982543\n",
      "138: mean_reward=49.0094727520511\n",
      "139: mean_reward=43.995532149879566\n",
      "140: mean_reward=48.473813456672204\n",
      "141: mean_reward=47.21924939645978\n",
      "142: mean_reward=43.877458975507196\n",
      "143: mean_reward=48.257994412233\n",
      "144: mean_reward=51.52716257821308\n",
      "145: mean_reward=42.587943730222975\n",
      "146: mean_reward=51.45110399488553\n",
      "147: mean_reward=58.72563381137972\n",
      "148: mean_reward=37.9690071509616\n",
      "149: mean_reward=47.1163844111196\n",
      "150: mean_reward=50.933806101075454\n",
      "151: mean_reward=55.93116797227208\n",
      "152: mean_reward=51.28350143676776\n",
      "153: mean_reward=50.772030600036466\n",
      "154: mean_reward=64.10464326204465\n",
      "155: mean_reward=70.35028364223199\n",
      "156: mean_reward=53.69842773135894\n",
      "157: mean_reward=71.10549498184314\n",
      "158: mean_reward=49.21371088198837\n",
      "159: mean_reward=63.60923007979849\n",
      "160: mean_reward=77.172197603116\n",
      "161: mean_reward=62.51877608473534\n",
      "162: mean_reward=71.19766574705773\n",
      "163: mean_reward=69.14780287520423\n",
      "164: mean_reward=53.74656629845472\n",
      "165: mean_reward=82.86103470317113\n",
      "166: mean_reward=76.48611995027468\n",
      "167: mean_reward=79.4989855012622\n",
      "168: mean_reward=78.45833538967261\n",
      "169: mean_reward=101.14243099542676\n",
      "170: mean_reward=76.24245018824658\n",
      "171: mean_reward=98.09194637970333\n",
      "172: mean_reward=68.59316368471977\n",
      "173: mean_reward=108.99591663706364\n",
      "174: mean_reward=82.31392631276535\n",
      "175: mean_reward=87.73496481700678\n",
      "176: mean_reward=97.42209688786372\n",
      "177: mean_reward=85.97500695983585\n",
      "178: mean_reward=88.48760165793621\n",
      "179: mean_reward=89.26658381080546\n",
      "180: mean_reward=78.70225603769502\n",
      "181: mean_reward=85.64109750304435\n",
      "182: mean_reward=70.62724007031903\n",
      "183: mean_reward=79.14369678827717\n",
      "184: mean_reward=70.37395295348016\n",
      "185: mean_reward=73.36713693238212\n",
      "186: mean_reward=88.34747863690282\n",
      "187: mean_reward=72.23438062330321\n",
      "188: mean_reward=120.2957406966949\n",
      "189: mean_reward=118.00026330125782\n",
      "190: mean_reward=128.64716986761053\n",
      "191: mean_reward=112.6308586343745\n",
      "192: mean_reward=153.20178414329246\n",
      "193: mean_reward=138.91569438557354\n",
      "194: mean_reward=178.5447369790306\n",
      "195: mean_reward=133.25502375256633\n",
      "196: mean_reward=179.0256356241801\n",
      "197: mean_reward=158.4455764368353\n",
      "198: mean_reward=180.5645862698403\n",
      "199: mean_reward=158.0963011855479\n",
      "200: mean_reward=150.665741755051\n",
      "201: mean_reward=140.86343334352026\n",
      "202: mean_reward=186.69361979283724\n",
      "203: mean_reward=225.5026941983603\n",
      "204: mean_reward=176.41342116304176\n",
      "205: mean_reward=176.58995513715865\n",
      "206: mean_reward=193.94609738640705\n",
      "207: mean_reward=195.032594507748\n",
      "208: mean_reward=202.06648617151393\n",
      "209: mean_reward=235.12373063164327\n",
      "210: mean_reward=220.9256824039916\n",
      "211: mean_reward=212.63998541203094\n",
      "212: mean_reward=210.21332840276466\n",
      "213: mean_reward=221.3351156924655\n",
      "214: mean_reward=230.70273776707572\n",
      "215: mean_reward=212.1065029679265\n",
      "216: mean_reward=210.95178935437912\n",
      "217: mean_reward=223.4987987433524\n",
      "218: mean_reward=231.59739037008185\n",
      "219: mean_reward=213.4260318200376\n",
      "220: mean_reward=209.5560539644388\n",
      "221: mean_reward=229.93803425299942\n",
      "222: mean_reward=200.18739643198413\n",
      "223: mean_reward=213.76698706687677\n",
      "224: mean_reward=211.69507880960109\n",
      "225: mean_reward=227.90384393258452\n",
      "226: mean_reward=232.92619088683142\n",
      "227: mean_reward=199.48165061746414\n",
      "228: mean_reward=228.85669801926377\n",
      "229: mean_reward=217.01138908838638\n",
      "230: mean_reward=212.201598604504\n",
      "231: mean_reward=225.5086125245151\n",
      "232: mean_reward=224.64455524429238\n",
      "233: mean_reward=224.78474698596975\n",
      "234: mean_reward=214.1089145110046\n",
      "235: mean_reward=240.7270695778644\n",
      "236: mean_reward=244.03193963577826\n",
      "237: mean_reward=246.47054330078902\n",
      "238: mean_reward=241.19887200554504\n",
      "239: mean_reward=245.1888803769537\n",
      "240: mean_reward=252.75269628469545\n",
      "241: mean_reward=216.90463686602885\n",
      "242: mean_reward=219.5421772886873\n",
      "243: mean_reward=250.40076893523943\n",
      "244: mean_reward=218.8596014946106\n",
      "245: mean_reward=237.9874206592188\n",
      "246: mean_reward=210.8186719305798\n",
      "247: mean_reward=238.47937399655123\n",
      "248: mean_reward=206.4129757667271\n",
      "249: mean_reward=208.7498615025466\n",
      "250: mean_reward=190.09872964017396\n",
      "251: mean_reward=202.142731853003\n",
      "252: mean_reward=175.62330691819716\n",
      "253: mean_reward=197.88539812913118\n",
      "254: mean_reward=208.979876182105\n",
      "255: mean_reward=156.87848525966413\n",
      "256: mean_reward=167.46579038344126\n",
      "257: mean_reward=211.35729612708616\n",
      "258: mean_reward=207.38457208144516\n",
      "259: mean_reward=178.45099338827706\n",
      "260: mean_reward=218.07487014614503\n",
      "261: mean_reward=196.5788011208392\n",
      "262: mean_reward=218.23319854191945\n",
      "263: mean_reward=205.73742069809316\n",
      "264: mean_reward=205.58411223712193\n",
      "265: mean_reward=183.92370617474407\n",
      "266: mean_reward=209.29205705433375\n",
      "267: mean_reward=177.03216632596636\n",
      "268: mean_reward=203.23394511810585\n",
      "269: mean_reward=168.97914989142802\n",
      "270: mean_reward=238.614375003909\n",
      "271: mean_reward=214.35452579424728\n",
      "272: mean_reward=229.72545276334418\n",
      "273: mean_reward=245.2237260718422\n",
      "274: mean_reward=227.20390215570674\n",
      "275: mean_reward=237.73630255775123\n",
      "276: mean_reward=222.57795949284954\n",
      "277: mean_reward=223.94395503189887\n",
      "278: mean_reward=214.5160694945742\n",
      "279: mean_reward=223.10164360446527\n",
      "280: mean_reward=236.62321574288208\n",
      "281: mean_reward=247.8594847986417\n",
      "282: mean_reward=210.1907864744717\n",
      "283: mean_reward=219.55196708119246\n",
      "284: mean_reward=226.50865611364253\n",
      "285: mean_reward=214.63125937190622\n",
      "286: mean_reward=195.03198102051647\n",
      "287: mean_reward=185.1734978149424\n",
      "288: mean_reward=149.4662601899162\n",
      "289: mean_reward=126.29729340959818\n",
      "290: mean_reward=166.49266306850183\n",
      "291: mean_reward=168.08456457632417\n",
      "292: mean_reward=146.47510678398538\n",
      "293: mean_reward=154.483576909521\n",
      "294: mean_reward=194.7085260906147\n",
      "295: mean_reward=238.8206580914313\n",
      "296: mean_reward=215.91174582735073\n",
      "297: mean_reward=242.58715130260833\n",
      "298: mean_reward=246.4432164688192\n",
      "299: mean_reward=220.80657973481254\n"
     ]
    }
   ],
   "source": [
    "agent = CEM(state_dim, action_n, hidden=64, lr=lr)\n",
    "\n",
    "for i in range(MAX_ITER):\n",
    "    batch_states, batch_actions, batch_rewards = generate_batch(env, agent, BATCH_SIZE, TRAJECTORY_LEN)\n",
    "    elite_states, elite_actions = get_elite_states(batch_states, batch_actions, batch_rewards, Q)\n",
    "    \n",
    "    mean_reward = np.mean(batch_rewards)\n",
    "    total_rewards.append({'agent': 'one_layer_64', 'epoch': i, 'reward': mean_reward})\n",
    "    agent.update_policy(elite_states, elite_actions)\n",
    "    print(f'{i}: mean_reward={mean_reward}')\n",
    "\n",
    "time_end = time.time()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0: mean_reward=-170.9517475155726\n",
      "1: mean_reward=-177.76396783949812\n",
      "2: mean_reward=-126.4649402815442\n",
      "3: mean_reward=-133.99747917274092\n",
      "4: mean_reward=-142.8822074646124\n",
      "5: mean_reward=-126.2294885014729\n",
      "6: mean_reward=-137.82938457314307\n",
      "7: mean_reward=-144.30658174206317\n",
      "8: mean_reward=-120.67569254207058\n",
      "9: mean_reward=-134.7147150647002\n",
      "10: mean_reward=-161.625951351328\n",
      "11: mean_reward=-119.36711716145406\n",
      "12: mean_reward=-134.6772499184125\n",
      "13: mean_reward=-125.51601967020125\n",
      "14: mean_reward=-102.96500345271593\n",
      "15: mean_reward=-98.0502944056614\n",
      "16: mean_reward=-116.23951306471827\n",
      "17: mean_reward=-91.00784719796397\n",
      "18: mean_reward=-92.5175231840244\n",
      "19: mean_reward=-71.82859532006995\n",
      "20: mean_reward=-101.19113173569457\n",
      "21: mean_reward=-86.63530398486206\n",
      "22: mean_reward=-62.83550259616471\n",
      "23: mean_reward=-96.53232173085266\n",
      "24: mean_reward=-75.73083271587015\n",
      "25: mean_reward=-101.95891483657512\n",
      "26: mean_reward=-145.97521332017277\n",
      "27: mean_reward=-151.06164894829138\n",
      "28: mean_reward=-192.13594390174913\n",
      "29: mean_reward=-178.36140707811904\n",
      "30: mean_reward=-170.6450745673541\n",
      "31: mean_reward=-166.8827302990395\n",
      "32: mean_reward=-114.03535316576152\n",
      "33: mean_reward=-79.92333926871342\n",
      "34: mean_reward=-92.08707452819561\n",
      "35: mean_reward=-105.88187600587972\n",
      "36: mean_reward=-101.6241988788814\n",
      "37: mean_reward=-100.19100092463948\n",
      "38: mean_reward=-80.40244571789131\n",
      "39: mean_reward=-63.61751234944044\n",
      "40: mean_reward=-73.16836098412293\n",
      "41: mean_reward=-63.26397390104035\n",
      "42: mean_reward=-54.552003606000916\n",
      "43: mean_reward=-53.863499704023745\n",
      "44: mean_reward=-79.32566543529708\n",
      "45: mean_reward=-65.70423608969637\n",
      "46: mean_reward=-75.6018564618577\n",
      "47: mean_reward=-74.39844965568005\n",
      "48: mean_reward=-86.36618267469078\n",
      "49: mean_reward=-80.98754008279897\n",
      "50: mean_reward=-100.41088277914945\n",
      "51: mean_reward=-94.77295462643674\n",
      "52: mean_reward=-90.72377686465215\n",
      "53: mean_reward=-82.74962506938041\n",
      "54: mean_reward=-106.7454632348377\n",
      "55: mean_reward=-90.42054296781178\n",
      "56: mean_reward=-89.15179727284027\n",
      "57: mean_reward=-91.62806681171756\n",
      "58: mean_reward=-88.54696633674088\n",
      "59: mean_reward=-76.9803853867282\n",
      "60: mean_reward=-73.27884497375584\n",
      "61: mean_reward=-101.79061839147133\n",
      "62: mean_reward=-109.16930452879343\n",
      "63: mean_reward=-115.21648557638103\n",
      "64: mean_reward=-121.55977870455115\n",
      "65: mean_reward=-108.98353601371669\n",
      "66: mean_reward=-116.23595643647609\n",
      "67: mean_reward=-110.98364232670144\n",
      "68: mean_reward=-88.53595042595745\n",
      "69: mean_reward=-121.28077543710657\n",
      "70: mean_reward=-120.08173394527083\n",
      "71: mean_reward=-100.7908258585473\n",
      "72: mean_reward=-114.3295461287043\n",
      "73: mean_reward=-104.57317299418123\n",
      "74: mean_reward=-96.10176704293487\n",
      "75: mean_reward=-77.33093395045445\n",
      "76: mean_reward=-85.682037898777\n",
      "77: mean_reward=-97.4177343392771\n",
      "78: mean_reward=-76.87299144333132\n",
      "79: mean_reward=-75.96845635432982\n",
      "80: mean_reward=-62.73483247467744\n",
      "81: mean_reward=-60.91316262606671\n",
      "82: mean_reward=-46.093665702592126\n",
      "83: mean_reward=-50.31850160667569\n",
      "84: mean_reward=-50.44463682491386\n",
      "85: mean_reward=-56.7127667066337\n",
      "86: mean_reward=-45.204115088019286\n",
      "87: mean_reward=-60.02755795531341\n",
      "88: mean_reward=-44.7763785724942\n",
      "89: mean_reward=-26.153310444903212\n",
      "90: mean_reward=-42.99426413643745\n",
      "91: mean_reward=-43.497595352905876\n",
      "92: mean_reward=-40.473119496547504\n",
      "93: mean_reward=-35.07448489195006\n",
      "94: mean_reward=-33.16216355678847\n",
      "95: mean_reward=-29.972236180570093\n",
      "96: mean_reward=-33.54157913722466\n",
      "97: mean_reward=-50.54563392060635\n",
      "98: mean_reward=-59.11071202940198\n",
      "99: mean_reward=-87.60035416628\n",
      "100: mean_reward=-58.31916072994234\n",
      "101: mean_reward=-51.58761013786096\n",
      "102: mean_reward=-91.18885143984258\n",
      "103: mean_reward=-49.32158612354295\n",
      "104: mean_reward=-80.59340172174147\n",
      "105: mean_reward=-46.222978766232806\n",
      "106: mean_reward=-66.99678051616687\n",
      "107: mean_reward=-57.40625844639177\n",
      "108: mean_reward=-51.31493467705063\n",
      "109: mean_reward=-50.51914446279978\n",
      "110: mean_reward=-54.23802552958376\n",
      "111: mean_reward=-59.805549466997874\n",
      "112: mean_reward=-58.762095570765524\n",
      "113: mean_reward=-57.04451359633725\n",
      "114: mean_reward=-43.78005668186383\n",
      "115: mean_reward=-38.07790139743196\n",
      "116: mean_reward=-43.54187032894339\n",
      "117: mean_reward=-50.692878883636205\n",
      "118: mean_reward=-36.9262214131973\n",
      "119: mean_reward=-42.110779362424594\n",
      "120: mean_reward=-39.67190901839028\n",
      "121: mean_reward=-52.18580469826921\n",
      "122: mean_reward=-65.72188086664251\n",
      "123: mean_reward=-76.06184290679307\n",
      "124: mean_reward=-81.49664607192783\n",
      "125: mean_reward=-92.84756586525819\n",
      "126: mean_reward=-78.32030664007199\n",
      "127: mean_reward=-70.9498830565393\n",
      "128: mean_reward=-64.37774720573859\n",
      "129: mean_reward=-48.0933703362531\n",
      "130: mean_reward=-36.84788841735873\n",
      "131: mean_reward=-36.54571828934274\n",
      "132: mean_reward=-35.11929935268197\n",
      "133: mean_reward=-39.16566619986921\n",
      "134: mean_reward=-32.093862595138006\n",
      "135: mean_reward=-33.200162025327714\n",
      "136: mean_reward=-12.27313038964012\n",
      "137: mean_reward=-44.51721731554513\n",
      "138: mean_reward=-11.193576833710663\n",
      "139: mean_reward=-30.089556797954874\n",
      "140: mean_reward=-9.07121916254534\n",
      "141: mean_reward=-11.899217107545685\n",
      "142: mean_reward=-8.319770474461537\n",
      "143: mean_reward=-18.98321426080583\n",
      "144: mean_reward=-9.347314287247162\n",
      "145: mean_reward=-27.66246843326878\n",
      "146: mean_reward=-15.77535821338298\n",
      "147: mean_reward=-8.768134307833742\n",
      "148: mean_reward=-26.850678383237295\n",
      "149: mean_reward=1.1519935828724552\n",
      "150: mean_reward=-21.322316983320164\n",
      "151: mean_reward=-25.774414711968465\n",
      "152: mean_reward=-14.795241377548475\n",
      "153: mean_reward=-21.39668541777387\n",
      "154: mean_reward=-25.136637865885085\n",
      "155: mean_reward=-32.40805455337165\n",
      "156: mean_reward=-28.122207725248824\n",
      "157: mean_reward=-29.351684387637125\n",
      "158: mean_reward=-30.17455497208412\n",
      "159: mean_reward=-28.089113807896325\n",
      "160: mean_reward=-30.42205526610163\n",
      "161: mean_reward=-42.771569194052965\n",
      "162: mean_reward=-12.947779404890966\n",
      "163: mean_reward=-29.359208130729684\n",
      "164: mean_reward=-28.08567259449327\n",
      "165: mean_reward=-23.57427969723021\n",
      "166: mean_reward=-29.91486779874087\n",
      "167: mean_reward=-34.21232311345586\n",
      "168: mean_reward=-31.221740220279358\n",
      "169: mean_reward=-37.043713468358085\n",
      "170: mean_reward=-43.04196854426135\n",
      "171: mean_reward=-24.31225654851804\n",
      "172: mean_reward=-20.10458355212619\n",
      "173: mean_reward=-31.71976087090103\n",
      "174: mean_reward=-13.314341716610624\n",
      "175: mean_reward=-20.9322310228963\n",
      "176: mean_reward=-13.665264025792379\n",
      "177: mean_reward=-13.125492847050452\n",
      "178: mean_reward=-4.146592804031131\n",
      "179: mean_reward=-22.905862716327377\n",
      "180: mean_reward=-10.506738327327193\n",
      "181: mean_reward=-10.680866024671705\n",
      "182: mean_reward=-16.696861833457564\n",
      "183: mean_reward=-16.926085157827174\n",
      "184: mean_reward=-9.829522584588616\n",
      "185: mean_reward=1.2223989149358436\n",
      "186: mean_reward=-14.576605969695093\n",
      "187: mean_reward=-14.086749757765567\n",
      "188: mean_reward=0.8938245087417254\n",
      "189: mean_reward=-12.479627499796885\n",
      "190: mean_reward=-10.379016133450403\n",
      "191: mean_reward=-1.3702585995682575\n",
      "192: mean_reward=-6.313020250352132\n",
      "193: mean_reward=19.766950253914615\n",
      "194: mean_reward=-3.5237830026682166\n",
      "195: mean_reward=0.565238811189952\n",
      "196: mean_reward=-6.309729824977385\n",
      "197: mean_reward=-1.0847466094268925\n",
      "198: mean_reward=-1.6374516967844\n",
      "199: mean_reward=4.576282764148188\n",
      "200: mean_reward=9.261097710797518\n",
      "201: mean_reward=-2.1129909563713314\n",
      "202: mean_reward=-10.310166480408123\n",
      "203: mean_reward=-7.592733421943822\n",
      "204: mean_reward=-1.7804713041572535\n",
      "205: mean_reward=14.040818556515609\n",
      "206: mean_reward=-0.25288270737560226\n",
      "207: mean_reward=-3.9965175868218843\n",
      "208: mean_reward=-0.219667243998228\n",
      "209: mean_reward=5.336113530746067\n",
      "210: mean_reward=4.848466634826342\n",
      "211: mean_reward=12.28720591073778\n",
      "212: mean_reward=4.996311856384494\n",
      "213: mean_reward=19.247063623938153\n",
      "214: mean_reward=18.81230914515951\n",
      "215: mean_reward=-4.036899336512244\n",
      "216: mean_reward=23.847350370121625\n",
      "217: mean_reward=25.889889666726287\n",
      "218: mean_reward=24.55738755323071\n",
      "219: mean_reward=23.18143592341247\n",
      "220: mean_reward=25.515250742755956\n",
      "221: mean_reward=25.544643185505876\n",
      "222: mean_reward=9.456206570830666\n",
      "223: mean_reward=26.78395163005575\n",
      "224: mean_reward=32.47426723682204\n",
      "225: mean_reward=18.02172896070578\n",
      "226: mean_reward=29.462557892613876\n",
      "227: mean_reward=34.05168244174933\n",
      "228: mean_reward=29.72743017043535\n",
      "229: mean_reward=32.254761230788674\n",
      "230: mean_reward=27.688020895458532\n",
      "231: mean_reward=27.395055130159662\n",
      "232: mean_reward=32.18494803314192\n",
      "233: mean_reward=31.71306497516136\n",
      "234: mean_reward=27.274710577159844\n",
      "235: mean_reward=32.77003039478496\n",
      "236: mean_reward=39.12571745784405\n",
      "237: mean_reward=20.28699457834079\n",
      "238: mean_reward=26.324763361554204\n",
      "239: mean_reward=21.235354661318784\n",
      "240: mean_reward=31.860107200642666\n",
      "241: mean_reward=24.37169060010539\n",
      "242: mean_reward=14.825404302866808\n",
      "243: mean_reward=30.29108155923729\n",
      "244: mean_reward=17.570817427287125\n",
      "245: mean_reward=35.94614258003504\n",
      "246: mean_reward=32.87751755304586\n",
      "247: mean_reward=-0.6460194676936666\n",
      "248: mean_reward=6.918296566880142\n",
      "249: mean_reward=7.802054529136568\n",
      "250: mean_reward=-12.6554172952518\n",
      "251: mean_reward=6.523612114807186\n",
      "252: mean_reward=6.4263013883680085\n",
      "253: mean_reward=2.545222098166424\n",
      "254: mean_reward=5.667421317007317\n",
      "255: mean_reward=22.251465595718194\n",
      "256: mean_reward=-1.7936819757803635\n",
      "257: mean_reward=14.652692529219726\n",
      "258: mean_reward=20.07462897105262\n",
      "259: mean_reward=5.631260782458011\n",
      "260: mean_reward=2.2962070349222117\n",
      "261: mean_reward=25.237685210773485\n",
      "262: mean_reward=20.967475692949943\n",
      "263: mean_reward=5.036539861434353\n",
      "264: mean_reward=-19.075259311548134\n",
      "265: mean_reward=14.339032368741218\n",
      "266: mean_reward=17.384239731858223\n",
      "267: mean_reward=31.03661656650838\n",
      "268: mean_reward=15.595316569132887\n",
      "269: mean_reward=23.258859699229255\n",
      "270: mean_reward=21.978100728756484\n",
      "271: mean_reward=13.181113970908823\n",
      "272: mean_reward=-0.5378874554353723\n",
      "273: mean_reward=16.96009176911223\n",
      "274: mean_reward=16.933318493887818\n",
      "275: mean_reward=-1.4768922128320299\n",
      "276: mean_reward=24.39235950742396\n",
      "277: mean_reward=15.194475830417987\n",
      "278: mean_reward=30.333715760682054\n",
      "279: mean_reward=25.684283085220912\n",
      "280: mean_reward=24.327492821130196\n",
      "281: mean_reward=48.61990540748817\n",
      "282: mean_reward=24.794565330837507\n",
      "283: mean_reward=24.334053333668507\n",
      "284: mean_reward=19.9905794482585\n",
      "285: mean_reward=28.075258097663394\n",
      "286: mean_reward=34.28344132537338\n",
      "287: mean_reward=30.187638804268435\n",
      "288: mean_reward=38.46244287664959\n",
      "289: mean_reward=37.34835207417576\n",
      "290: mean_reward=21.519810772096424\n",
      "291: mean_reward=51.03806077853758\n",
      "292: mean_reward=41.03479192536845\n",
      "293: mean_reward=42.062959736734655\n",
      "294: mean_reward=42.370361407600214\n",
      "295: mean_reward=44.174765381351136\n",
      "296: mean_reward=31.90973743657049\n",
      "297: mean_reward=24.80833767723487\n",
      "298: mean_reward=40.6250895555506\n",
      "299: mean_reward=40.1415825701225\n"
     ]
    }
   ],
   "source": [
    "agent = CEM(state_dim, action_n, hidden=256, lr=lr)\n",
    "\n",
    "for i in range(MAX_ITER):\n",
    "    batch_states, batch_actions, batch_rewards = generate_batch(env, agent, BATCH_SIZE, TRAJECTORY_LEN)\n",
    "    elite_states, elite_actions = get_elite_states(batch_states, batch_actions, batch_rewards, Q)\n",
    "    \n",
    "    mean_reward = np.mean(batch_rewards)\n",
    "    total_rewards.append({'agent': 'one_layer_256', 'epoch': i, 'reward': mean_reward})\n",
    "    agent.update_policy(elite_states, elite_actions)\n",
    "    print(f'{i}: mean_reward={mean_reward}')\n",
    "\n",
    "time_end = time.time()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Результаты работы нейросети с разным количество нейронов"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.plotly.v1+json": {
       "config": {
        "plotlyServerURL": "https://plot.ly"
       },
       "data": [
        {
         "hovertemplate": "agent=one_layer_16<br>epoch=%{x}<br>reward=%{y}<extra></extra>",
         "legendgroup": "one_layer_16",
         "line": {
          "color": "#636efa",
          "dash": "solid"
         },
         "marker": {
          "symbol": "circle"
         },
         "mode": "lines",
         "name": "one_layer_16",
         "orientation": "v",
         "showlegend": true,
         "type": "scatter",
         "x": [
          0,
          1,
          2,
          3,
          4,
          5,
          6,
          7,
          8,
          9,
          10,
          11,
          12,
          13,
          14,
          15,
          16,
          17,
          18,
          19,
          20,
          21,
          22,
          23,
          24,
          25,
          26,
          27,
          28,
          29,
          30,
          31,
          32,
          33,
          34,
          35,
          36,
          37,
          38,
          39,
          40,
          41,
          42,
          43,
          44,
          45,
          46,
          47,
          48,
          49,
          50,
          51,
          52,
          53,
          54,
          55,
          56,
          57,
          58,
          59,
          60,
          61,
          62,
          63,
          64,
          65,
          66,
          67,
          68,
          69,
          70,
          71,
          72,
          73,
          74,
          75,
          76,
          77,
          78,
          79,
          80,
          81,
          82,
          83,
          84,
          85,
          86,
          87,
          88,
          89,
          90,
          91,
          92,
          93,
          94,
          95,
          96,
          97,
          98,
          99,
          100,
          101,
          102,
          103,
          104,
          105,
          106,
          107,
          108,
          109,
          110,
          111,
          112,
          113,
          114,
          115,
          116,
          117,
          118,
          119,
          120,
          121,
          122,
          123,
          124,
          125,
          126,
          127,
          128,
          129,
          130,
          131,
          132,
          133,
          134,
          135,
          136,
          137,
          138,
          139,
          140,
          141,
          142,
          143,
          144,
          145,
          146,
          147,
          148,
          149,
          150,
          151,
          152,
          153,
          154,
          155,
          156,
          157,
          158,
          159,
          160,
          161,
          162,
          163,
          164,
          165,
          166,
          167,
          168,
          169,
          170,
          171,
          172,
          173,
          174,
          175,
          176,
          177,
          178,
          179,
          180,
          181,
          182,
          183,
          184,
          185,
          186,
          187,
          188,
          189,
          190,
          191,
          192,
          193,
          194,
          195,
          196,
          197,
          198,
          199,
          200,
          201,
          202,
          203,
          204,
          205,
          206,
          207,
          208,
          209,
          210,
          211,
          212,
          213,
          214,
          215,
          216,
          217,
          218,
          219,
          220,
          221,
          222,
          223,
          224,
          225,
          226,
          227,
          228,
          229,
          230,
          231,
          232,
          233,
          234,
          235,
          236,
          237,
          238,
          239,
          240,
          241,
          242,
          243,
          244,
          245,
          246,
          247,
          248,
          249,
          250,
          251,
          252,
          253,
          254,
          255,
          256,
          257,
          258,
          259,
          260,
          261,
          262,
          263,
          264,
          265,
          266,
          267,
          268,
          269,
          270,
          271,
          272,
          273,
          274,
          275,
          276,
          277,
          278,
          279,
          280,
          281,
          282,
          283,
          284,
          285,
          286,
          287,
          288,
          289,
          290,
          291,
          292,
          293,
          294,
          295,
          296,
          297,
          298,
          299
         ],
         "xaxis": "x",
         "y": [
          -191.48395824124694,
          -174.2419655171212,
          -208.92693535157505,
          -205.46261584454933,
          -189.12988426996998,
          -177.145662975239,
          -163.50331161796714,
          -173.64757818948314,
          -180.31325101368782,
          -175.11206418323044,
          -165.17564633666848,
          -191.588429659361,
          -172.04514112870672,
          -166.550656179244,
          -149.70976027911104,
          -156.3929513224928,
          -174.412732258016,
          -148.71432268954584,
          -170.89355312810065,
          -140.32884151437483,
          -166.3467893099404,
          -160.83282092929824,
          -149.57180365839602,
          -147.77366404994933,
          -147.50249041027158,
          -149.52373063988506,
          -150.93125737988822,
          -136.11214449074043,
          -150.01022350988612,
          -131.64334625940097,
          -160.46679343842663,
          -134.46226844423595,
          -140.5845685018228,
          -133.113411361467,
          -137.4436148863879,
          -145.8258655532491,
          -159.52866902818153,
          -136.65099028706686,
          -127.57253130968333,
          -134.29273250574647,
          -136.03672168868397,
          -140.14052866448833,
          -125.4890346064967,
          -126.5207144947114,
          -133.15765485762438,
          -142.7267167833463,
          -139.6806414030879,
          -128.83206838011654,
          -113.74009682220147,
          -113.46172987384666,
          -108.28317000328923,
          -114.37313744029382,
          -106.38155525690563,
          -114.48312547412884,
          -121.86385543278811,
          -106.20327065977266,
          -101.4428667328588,
          -99.66222898679392,
          -89.56847167599831,
          -103.15090774620599,
          -102.71377918920473,
          -100.60738593235685,
          -98.3424238446244,
          -82.9747717428105,
          -87.30679880498423,
          -86.75966028779372,
          -78.5155873073602,
          -82.16431985852141,
          -80.07883726946012,
          -68.13559841512038,
          -67.98038870430331,
          -69.9029145691322,
          -80.83450666254966,
          -73.93851730416173,
          -71.59019820292839,
          -70.24430752705464,
          -69.39465455217952,
          -68.58985825874544,
          -65.577196234761,
          -88.18172609958587,
          -87.51982656874597,
          -96.49386799718394,
          -100.0382950841626,
          -96.13715812560186,
          -121.57028762174872,
          -127.84776265294242,
          -83.947639208687,
          -53.40416201852772,
          -62.720491098916234,
          -54.76961715353745,
          -39.33442438919733,
          -50.46840710604414,
          -29.48126526529115,
          -28.82051456550058,
          -25.705225454842584,
          -28.82179548748643,
          -32.593683323589595,
          -33.282161830512536,
          -25.774719834440603,
          -34.78881777186409,
          -31.39798227181042,
          -30.518425946671915,
          -17.685519203106015,
          -25.34374499176195,
          -23.91580058826111,
          -11.111352600941286,
          -7.843867714473885,
          -30.25952843416491,
          -12.753268503814429,
          -25.081305527982593,
          -21.865988643803806,
          -17.049191313652333,
          -23.597800921725256,
          -33.95538952464531,
          -10.879999154169191,
          -35.865067816296225,
          -35.14494884125753,
          -28.786639150310066,
          -26.88193585589733,
          -20.940035621228375,
          -66.69271908634876,
          -36.272125096622084,
          -17.035632098868767,
          -17.98692035881015,
          8.807671480612619,
          -1.8948380738902835,
          -2.562068739692898,
          3.127878971481144,
          -22.981213901321823,
          -13.141905048262135,
          -7.317701948313264,
          1.2930298016068473,
          -1.8523804515429811,
          -0.2511646132291679,
          -3.73332386238066,
          0.704332384706239,
          -0.015760317898549373,
          10.503069989447129,
          3.4693729782912577,
          7.550792085004187,
          0.9771266033635112,
          5.4236147248777025,
          2.7832608366808307,
          7.516513075223603,
          5.18824238463298,
          1.3582244826275962,
          11.364489990491435,
          -2.0159247585320634,
          3.8716048633147455,
          8.110069713233493,
          9.974392679239614,
          1.2840782501684231,
          18.549733739623694,
          8.737357642606726,
          5.733940816098129,
          9.58813531938529,
          7.8008903035826345,
          16.881169415761995,
          9.518189783247898,
          29.313608342349816,
          0.9110550789168101,
          28.715895229089462,
          14.51227513914978,
          13.698932616241922,
          10.601869512911156,
          8.936817428604515,
          9.917099169117025,
          7.06568350078069,
          -8.561953019685967,
          25.83458387278872,
          20.716133065420475,
          18.19683473064717,
          11.139230089476737,
          1.0537440722564981,
          29.640456143148754,
          7.756538626727352,
          19.886234611173577,
          4.6301969501348506,
          3.940023873681913,
          17.663151890124954,
          27.35883102648985,
          1.9864664123298925,
          11.0022854623214,
          12.566493291129234,
          31.187999403090316,
          17.41556480720402,
          32.65472889053723,
          15.853350551971925,
          4.817504218281395,
          21.77804858129735,
          22.525059007041037,
          24.15251710424244,
          6.11013048181234,
          2.9469858625268524,
          19.01276980700567,
          12.823131197625864,
          15.386956419848136,
          34.2878907563467,
          8.192453699804185,
          47.1483493960018,
          30.466564653374782,
          34.39981619759888,
          13.609141072825537,
          24.144627350257107,
          15.203683689458307,
          6.735947665758631,
          11.845531573101516,
          22.989628641068304,
          12.487632905243402,
          26.83634132583146,
          30.4295497676832,
          45.61442542380512,
          25.149897470414086,
          28.63055675490099,
          11.87016596332986,
          3.2288667217968,
          26.14242232047566,
          28.061888516064492,
          15.191295269875779,
          29.996809969567394,
          40.20246499657986,
          33.96833407520448,
          19.780456300768172,
          31.417136966378163,
          36.36323470462194,
          44.19656439380611,
          31.392350746583226,
          31.14698465181083,
          51.77685507451877,
          35.054655004412126,
          36.289815566303844,
          19.746671537470178,
          38.065853823677074,
          28.799128347774946,
          45.07792579651858,
          44.722728771826496,
          44.29433856620455,
          38.414497421966594,
          30.056434489287536,
          49.584519845414746,
          31.605342784770297,
          40.795516383397604,
          36.33707658740168,
          23.506363476165888,
          52.04034190232488,
          41.99095566336272,
          40.50225480395086,
          47.43011770146478,
          52.17944302514177,
          53.51042987679976,
          25.515750482943716,
          39.80725760897113,
          31.01699867059484,
          27.01334622119042,
          45.52736559467989,
          16.56483027159445,
          39.095184829634455,
          39.31686602041005,
          24.917721583814146,
          45.70276882216525,
          25.099014663419293,
          51.14271598054213,
          33.60534043065246,
          29.55916674283266,
          57.973387632058056,
          43.71496988430089,
          41.27014910539738,
          6.617499611740201,
          25.411448329270996,
          18.98023043217309,
          49.39374929418386,
          40.76402548232863,
          53.30916471449698,
          65.64040034859055,
          74.59536604716075,
          60.95497886527809,
          36.38704212180033,
          29.052181532819223,
          38.172928738784755,
          52.20749549721881,
          39.7358554482403,
          64.20894985642494,
          38.215187537623564,
          31.957273902421797,
          83.3442428996488,
          58.5267947564619,
          88.68334660841406,
          70.29136948018099,
          74.98229320773639,
          51.70662403477471,
          59.79763994074731,
          80.90043650219191,
          43.14782029196843,
          63.8116140960104,
          88.40721671973489,
          60.700501828181935,
          81.70004296782179,
          78.02163536635342,
          92.12215925082644,
          82.99980557416237
         ],
         "yaxis": "y"
        },
        {
         "hovertemplate": "agent=one_layer_64<br>epoch=%{x}<br>reward=%{y}<extra></extra>",
         "legendgroup": "one_layer_64",
         "line": {
          "color": "#EF553B",
          "dash": "solid"
         },
         "marker": {
          "symbol": "circle"
         },
         "mode": "lines",
         "name": "one_layer_64",
         "orientation": "v",
         "showlegend": true,
         "type": "scatter",
         "x": [
          0,
          1,
          2,
          3,
          4,
          5,
          6,
          7,
          8,
          9,
          10,
          11,
          12,
          13,
          14,
          15,
          16,
          17,
          18,
          19,
          20,
          21,
          22,
          23,
          24,
          25,
          26,
          27,
          28,
          29,
          30,
          31,
          32,
          33,
          34,
          35,
          36,
          37,
          38,
          39,
          40,
          41,
          42,
          43,
          44,
          45,
          46,
          47,
          48,
          49,
          50,
          51,
          52,
          53,
          54,
          55,
          56,
          57,
          58,
          59,
          60,
          61,
          62,
          63,
          64,
          65,
          66,
          67,
          68,
          69,
          70,
          71,
          72,
          73,
          74,
          75,
          76,
          77,
          78,
          79,
          80,
          81,
          82,
          83,
          84,
          85,
          86,
          87,
          88,
          89,
          90,
          91,
          92,
          93,
          94,
          95,
          96,
          97,
          98,
          99,
          100,
          101,
          102,
          103,
          104,
          105,
          106,
          107,
          108,
          109,
          110,
          111,
          112,
          113,
          114,
          115,
          116,
          117,
          118,
          119,
          120,
          121,
          122,
          123,
          124,
          125,
          126,
          127,
          128,
          129,
          130,
          131,
          132,
          133,
          134,
          135,
          136,
          137,
          138,
          139,
          140,
          141,
          142,
          143,
          144,
          145,
          146,
          147,
          148,
          149,
          150,
          151,
          152,
          153,
          154,
          155,
          156,
          157,
          158,
          159,
          160,
          161,
          162,
          163,
          164,
          165,
          166,
          167,
          168,
          169,
          170,
          171,
          172,
          173,
          174,
          175,
          176,
          177,
          178,
          179,
          180,
          181,
          182,
          183,
          184,
          185,
          186,
          187,
          188,
          189,
          190,
          191,
          192,
          193,
          194,
          195,
          196,
          197,
          198,
          199,
          200,
          201,
          202,
          203,
          204,
          205,
          206,
          207,
          208,
          209,
          210,
          211,
          212,
          213,
          214,
          215,
          216,
          217,
          218,
          219,
          220,
          221,
          222,
          223,
          224,
          225,
          226,
          227,
          228,
          229,
          230,
          231,
          232,
          233,
          234,
          235,
          236,
          237,
          238,
          239,
          240,
          241,
          242,
          243,
          244,
          245,
          246,
          247,
          248,
          249,
          250,
          251,
          252,
          253,
          254,
          255,
          256,
          257,
          258,
          259,
          260,
          261,
          262,
          263,
          264,
          265,
          266,
          267,
          268,
          269,
          270,
          271,
          272,
          273,
          274,
          275,
          276,
          277,
          278,
          279,
          280,
          281,
          282,
          283,
          284,
          285,
          286,
          287,
          288,
          289,
          290,
          291,
          292,
          293,
          294,
          295,
          296,
          297,
          298,
          299
         ],
         "xaxis": "x",
         "y": [
          -150.08397642617263,
          -153.8781485057967,
          -134.68879070115284,
          -170.11063683273758,
          -129.81758142493538,
          -140.37314885070774,
          -139.72323002504956,
          -135.48878488520876,
          -126.86427345735993,
          -133.98498217638763,
          -115.63781789412015,
          -120.91872621527631,
          -126.43047371608245,
          -110.58195337311831,
          -133.63219182848368,
          -121.83627462981207,
          -118.98237893094343,
          -120.09562860469279,
          -109.90294009616127,
          -119.30867288377065,
          -115.17798873414577,
          -118.2156888908358,
          -99.16318635243547,
          -97.2033748049157,
          -94.56923364631061,
          -93.74715547046318,
          -93.91762917475411,
          -88.11654764737101,
          -76.60250902218405,
          -71.51362023250384,
          -79.41982289278587,
          -75.67304013920273,
          -82.02836469922892,
          -84.50145997035287,
          -87.63809849713732,
          -87.40967324731446,
          -80.00141521767857,
          -69.97076227694257,
          -50.881232950465744,
          -80.82609818939196,
          -68.85046200786896,
          -77.75173917499812,
          -98.30522660685033,
          -90.06135559732088,
          -82.49725935818743,
          -77.17284191118017,
          -102.46679907299072,
          -66.84664369536613,
          -104.84079745197772,
          -75.64076059188345,
          -94.35945357487824,
          -83.61271075812785,
          -66.5405320213036,
          -37.845080891515124,
          -37.98859733567181,
          -0.3206933525731121,
          -6.322382867156105,
          -6.907817664524148,
          -0.16258589631108009,
          -3.1639036050193226,
          -0.5751866964930116,
          -3.636236181942628,
          0.6119624938452037,
          8.502297257595004,
          0.3218439535259279,
          4.301574046316088,
          10.532575800627855,
          7.457865646052299,
          7.204042946930567,
          0.42375903232003453,
          6.064804441395823,
          7.344134522731315,
          9.609175606370654,
          7.435331783342779,
          0.8140525723014775,
          16.100868483861905,
          17.411621704455165,
          17.7361602558687,
          14.736032290678331,
          16.01372291919171,
          14.444324657339342,
          23.89847533096247,
          16.69276557299888,
          22.019613821946518,
          27.106965985962088,
          12.900205266042777,
          5.929614493502052,
          7.693551326044623,
          10.628124627799417,
          13.488065563536065,
          -1.9412531094830654,
          9.110574879764064,
          5.400998174863286,
          20.32696802764212,
          16.584529600713758,
          12.75386989277677,
          20.138730783705988,
          30.43808727877549,
          23.09084035840794,
          36.57686787244728,
          36.32965893986125,
          35.534874514996396,
          40.3399429227545,
          39.17214937677715,
          34.78476129705128,
          44.28381289668914,
          38.335921455914516,
          53.14719635770068,
          43.87528735094407,
          43.219524500323544,
          49.361647157886935,
          38.110904370324555,
          45.00740906361967,
          43.81904574192349,
          46.792770191653005,
          49.184766278308096,
          37.20756746234209,
          47.72191166342627,
          41.271525293864435,
          27.01347532883728,
          41.25366111673461,
          42.65852005816793,
          48.270491729630464,
          49.85862823360869,
          49.19881907512676,
          40.85203868105165,
          32.56910324421293,
          35.948871037540755,
          61.311606933026795,
          42.45945934369074,
          51.90118107281102,
          49.138011525303746,
          48.159328899574014,
          59.42954680692923,
          66.20175432664855,
          56.81329607625882,
          61.262030544652944,
          67.0776006982543,
          49.0094727520511,
          43.995532149879566,
          48.473813456672204,
          47.21924939645978,
          43.877458975507196,
          48.257994412233,
          51.52716257821308,
          42.587943730222975,
          51.45110399488553,
          58.72563381137972,
          37.9690071509616,
          47.1163844111196,
          50.933806101075454,
          55.93116797227208,
          51.28350143676776,
          50.772030600036466,
          64.10464326204465,
          70.35028364223199,
          53.69842773135894,
          71.10549498184314,
          49.21371088198837,
          63.60923007979849,
          77.172197603116,
          62.51877608473534,
          71.19766574705773,
          69.14780287520423,
          53.74656629845472,
          82.86103470317113,
          76.48611995027468,
          79.4989855012622,
          78.45833538967261,
          101.14243099542676,
          76.24245018824658,
          98.09194637970333,
          68.59316368471977,
          108.99591663706364,
          82.31392631276535,
          87.73496481700678,
          97.42209688786372,
          85.97500695983585,
          88.48760165793621,
          89.26658381080546,
          78.70225603769502,
          85.64109750304435,
          70.62724007031903,
          79.14369678827717,
          70.37395295348016,
          73.36713693238212,
          88.34747863690282,
          72.23438062330321,
          120.2957406966949,
          118.00026330125782,
          128.64716986761053,
          112.6308586343745,
          153.20178414329246,
          138.91569438557354,
          178.5447369790306,
          133.25502375256633,
          179.0256356241801,
          158.4455764368353,
          180.5645862698403,
          158.0963011855479,
          150.665741755051,
          140.86343334352026,
          186.69361979283724,
          225.5026941983603,
          176.41342116304176,
          176.58995513715865,
          193.94609738640705,
          195.032594507748,
          202.06648617151393,
          235.12373063164327,
          220.9256824039916,
          212.63998541203094,
          210.21332840276466,
          221.3351156924655,
          230.70273776707572,
          212.1065029679265,
          210.95178935437912,
          223.4987987433524,
          231.59739037008185,
          213.4260318200376,
          209.5560539644388,
          229.93803425299942,
          200.18739643198413,
          213.76698706687677,
          211.69507880960109,
          227.90384393258452,
          232.92619088683142,
          199.48165061746414,
          228.85669801926377,
          217.01138908838638,
          212.201598604504,
          225.5086125245151,
          224.64455524429238,
          224.78474698596975,
          214.1089145110046,
          240.7270695778644,
          244.03193963577826,
          246.47054330078902,
          241.19887200554504,
          245.1888803769537,
          252.75269628469545,
          216.90463686602885,
          219.5421772886873,
          250.40076893523943,
          218.8596014946106,
          237.9874206592188,
          210.8186719305798,
          238.47937399655123,
          206.4129757667271,
          208.7498615025466,
          190.09872964017396,
          202.142731853003,
          175.62330691819716,
          197.88539812913118,
          208.979876182105,
          156.87848525966413,
          167.46579038344126,
          211.35729612708616,
          207.38457208144516,
          178.45099338827706,
          218.07487014614503,
          196.5788011208392,
          218.23319854191945,
          205.73742069809316,
          205.58411223712193,
          183.92370617474407,
          209.29205705433375,
          177.03216632596636,
          203.23394511810585,
          168.97914989142802,
          238.614375003909,
          214.35452579424728,
          229.72545276334418,
          245.2237260718422,
          227.20390215570674,
          237.73630255775123,
          222.57795949284954,
          223.94395503189887,
          214.5160694945742,
          223.10164360446527,
          236.62321574288208,
          247.8594847986417,
          210.1907864744717,
          219.55196708119246,
          226.50865611364253,
          214.63125937190622,
          195.03198102051647,
          185.1734978149424,
          149.4662601899162,
          126.29729340959818,
          166.49266306850183,
          168.08456457632417,
          146.47510678398538,
          154.483576909521,
          194.7085260906147,
          238.8206580914313,
          215.91174582735073,
          242.58715130260833,
          246.4432164688192,
          220.80657973481254
         ],
         "yaxis": "y"
        },
        {
         "hovertemplate": "agent=one_layer_256<br>epoch=%{x}<br>reward=%{y}<extra></extra>",
         "legendgroup": "one_layer_256",
         "line": {
          "color": "#00cc96",
          "dash": "solid"
         },
         "marker": {
          "symbol": "circle"
         },
         "mode": "lines",
         "name": "one_layer_256",
         "orientation": "v",
         "showlegend": true,
         "type": "scatter",
         "x": [
          0,
          1,
          2,
          3,
          4,
          5,
          6,
          7,
          8,
          9,
          10,
          11,
          12,
          13,
          14,
          15,
          16,
          17,
          18,
          19,
          20,
          21,
          22,
          23,
          24,
          25,
          26,
          27,
          28,
          29,
          30,
          31,
          32,
          33,
          34,
          35,
          36,
          37,
          38,
          39,
          40,
          41,
          42,
          43,
          44,
          45,
          46,
          47,
          48,
          49,
          50,
          51,
          52,
          53,
          54,
          55,
          56,
          57,
          58,
          59,
          60,
          61,
          62,
          63,
          64,
          65,
          66,
          67,
          68,
          69,
          70,
          71,
          72,
          73,
          74,
          75,
          76,
          77,
          78,
          79,
          80,
          81,
          82,
          83,
          84,
          85,
          86,
          87,
          88,
          89,
          90,
          91,
          92,
          93,
          94,
          95,
          96,
          97,
          98,
          99,
          100,
          101,
          102,
          103,
          104,
          105,
          106,
          107,
          108,
          109,
          110,
          111,
          112,
          113,
          114,
          115,
          116,
          117,
          118,
          119,
          120,
          121,
          122,
          123,
          124,
          125,
          126,
          127,
          128,
          129,
          130,
          131,
          132,
          133,
          134,
          135,
          136,
          137,
          138,
          139,
          140,
          141,
          142,
          143,
          144,
          145,
          146,
          147,
          148,
          149,
          150,
          151,
          152,
          153,
          154,
          155,
          156,
          157,
          158,
          159,
          160,
          161,
          162,
          163,
          164,
          165,
          166,
          167,
          168,
          169,
          170,
          171,
          172,
          173,
          174,
          175,
          176,
          177,
          178,
          179,
          180,
          181,
          182,
          183,
          184,
          185,
          186,
          187,
          188,
          189,
          190,
          191,
          192,
          193,
          194,
          195,
          196,
          197,
          198,
          199,
          200,
          201,
          202,
          203,
          204,
          205,
          206,
          207,
          208,
          209,
          210,
          211,
          212,
          213,
          214,
          215,
          216,
          217,
          218,
          219,
          220,
          221,
          222,
          223,
          224,
          225,
          226,
          227,
          228,
          229,
          230,
          231,
          232,
          233,
          234,
          235,
          236,
          237,
          238,
          239,
          240,
          241,
          242,
          243,
          244,
          245,
          246,
          247,
          248,
          249,
          250,
          251,
          252,
          253,
          254,
          255,
          256,
          257,
          258,
          259,
          260,
          261,
          262,
          263,
          264,
          265,
          266,
          267,
          268,
          269,
          270,
          271,
          272,
          273,
          274,
          275,
          276,
          277,
          278,
          279,
          280,
          281,
          282,
          283,
          284,
          285,
          286,
          287,
          288,
          289,
          290,
          291,
          292,
          293,
          294,
          295,
          296,
          297,
          298,
          299
         ],
         "xaxis": "x",
         "y": [
          -170.9517475155726,
          -177.76396783949812,
          -126.4649402815442,
          -133.99747917274092,
          -142.8822074646124,
          -126.2294885014729,
          -137.82938457314307,
          -144.30658174206317,
          -120.67569254207058,
          -134.7147150647002,
          -161.625951351328,
          -119.36711716145406,
          -134.6772499184125,
          -125.51601967020125,
          -102.96500345271593,
          -98.0502944056614,
          -116.23951306471827,
          -91.00784719796397,
          -92.5175231840244,
          -71.82859532006995,
          -101.19113173569457,
          -86.63530398486206,
          -62.83550259616471,
          -96.53232173085266,
          -75.73083271587015,
          -101.95891483657512,
          -145.97521332017277,
          -151.06164894829138,
          -192.13594390174913,
          -178.36140707811904,
          -170.6450745673541,
          -166.8827302990395,
          -114.03535316576152,
          -79.92333926871342,
          -92.08707452819561,
          -105.88187600587972,
          -101.6241988788814,
          -100.19100092463948,
          -80.40244571789131,
          -63.61751234944044,
          -73.16836098412293,
          -63.26397390104035,
          -54.552003606000916,
          -53.863499704023745,
          -79.32566543529708,
          -65.70423608969637,
          -75.6018564618577,
          -74.39844965568005,
          -86.36618267469078,
          -80.98754008279897,
          -100.41088277914945,
          -94.77295462643674,
          -90.72377686465215,
          -82.74962506938041,
          -106.7454632348377,
          -90.42054296781178,
          -89.15179727284027,
          -91.62806681171756,
          -88.54696633674088,
          -76.9803853867282,
          -73.27884497375584,
          -101.79061839147133,
          -109.16930452879343,
          -115.21648557638103,
          -121.55977870455115,
          -108.98353601371669,
          -116.23595643647609,
          -110.98364232670144,
          -88.53595042595745,
          -121.28077543710657,
          -120.08173394527083,
          -100.7908258585473,
          -114.3295461287043,
          -104.57317299418123,
          -96.10176704293487,
          -77.33093395045445,
          -85.682037898777,
          -97.4177343392771,
          -76.87299144333132,
          -75.96845635432982,
          -62.73483247467744,
          -60.91316262606671,
          -46.093665702592126,
          -50.31850160667569,
          -50.44463682491386,
          -56.7127667066337,
          -45.204115088019286,
          -60.02755795531341,
          -44.7763785724942,
          -26.153310444903212,
          -42.99426413643745,
          -43.497595352905876,
          -40.473119496547504,
          -35.07448489195006,
          -33.16216355678847,
          -29.972236180570093,
          -33.54157913722466,
          -50.54563392060635,
          -59.11071202940198,
          -87.60035416628,
          -58.31916072994234,
          -51.58761013786096,
          -91.18885143984258,
          -49.32158612354295,
          -80.59340172174147,
          -46.222978766232806,
          -66.99678051616687,
          -57.40625844639177,
          -51.31493467705063,
          -50.51914446279978,
          -54.23802552958376,
          -59.805549466997874,
          -58.762095570765524,
          -57.04451359633725,
          -43.78005668186383,
          -38.07790139743196,
          -43.54187032894339,
          -50.692878883636205,
          -36.9262214131973,
          -42.110779362424594,
          -39.67190901839028,
          -52.18580469826921,
          -65.72188086664251,
          -76.06184290679307,
          -81.49664607192783,
          -92.84756586525819,
          -78.32030664007199,
          -70.9498830565393,
          -64.37774720573859,
          -48.0933703362531,
          -36.84788841735873,
          -36.54571828934274,
          -35.11929935268197,
          -39.16566619986921,
          -32.093862595138006,
          -33.200162025327714,
          -12.27313038964012,
          -44.51721731554513,
          -11.193576833710663,
          -30.089556797954874,
          -9.07121916254534,
          -11.899217107545685,
          -8.319770474461537,
          -18.98321426080583,
          -9.347314287247162,
          -27.66246843326878,
          -15.77535821338298,
          -8.768134307833742,
          -26.850678383237295,
          1.1519935828724552,
          -21.322316983320164,
          -25.774414711968465,
          -14.795241377548475,
          -21.39668541777387,
          -25.136637865885085,
          -32.40805455337165,
          -28.122207725248824,
          -29.351684387637125,
          -30.17455497208412,
          -28.089113807896325,
          -30.42205526610163,
          -42.771569194052965,
          -12.947779404890966,
          -29.359208130729684,
          -28.08567259449327,
          -23.57427969723021,
          -29.91486779874087,
          -34.21232311345586,
          -31.221740220279358,
          -37.043713468358085,
          -43.04196854426135,
          -24.31225654851804,
          -20.10458355212619,
          -31.71976087090103,
          -13.314341716610624,
          -20.9322310228963,
          -13.665264025792379,
          -13.125492847050452,
          -4.146592804031131,
          -22.905862716327377,
          -10.506738327327193,
          -10.680866024671705,
          -16.696861833457564,
          -16.926085157827174,
          -9.829522584588616,
          1.2223989149358436,
          -14.576605969695093,
          -14.086749757765567,
          0.8938245087417254,
          -12.479627499796885,
          -10.379016133450403,
          -1.3702585995682575,
          -6.313020250352132,
          19.766950253914615,
          -3.5237830026682166,
          0.565238811189952,
          -6.309729824977385,
          -1.0847466094268925,
          -1.6374516967844,
          4.576282764148188,
          9.261097710797518,
          -2.1129909563713314,
          -10.310166480408123,
          -7.592733421943822,
          -1.7804713041572535,
          14.040818556515609,
          -0.25288270737560226,
          -3.9965175868218843,
          -0.219667243998228,
          5.336113530746067,
          4.848466634826342,
          12.28720591073778,
          4.996311856384494,
          19.247063623938153,
          18.81230914515951,
          -4.036899336512244,
          23.847350370121625,
          25.889889666726287,
          24.55738755323071,
          23.18143592341247,
          25.515250742755956,
          25.544643185505876,
          9.456206570830666,
          26.78395163005575,
          32.47426723682204,
          18.02172896070578,
          29.462557892613876,
          34.05168244174933,
          29.72743017043535,
          32.254761230788674,
          27.688020895458532,
          27.395055130159662,
          32.18494803314192,
          31.71306497516136,
          27.274710577159844,
          32.77003039478496,
          39.12571745784405,
          20.28699457834079,
          26.324763361554204,
          21.235354661318784,
          31.860107200642666,
          24.37169060010539,
          14.825404302866808,
          30.29108155923729,
          17.570817427287125,
          35.94614258003504,
          32.87751755304586,
          -0.6460194676936666,
          6.918296566880142,
          7.802054529136568,
          -12.6554172952518,
          6.523612114807186,
          6.4263013883680085,
          2.545222098166424,
          5.667421317007317,
          22.251465595718194,
          -1.7936819757803635,
          14.652692529219726,
          20.07462897105262,
          5.631260782458011,
          2.2962070349222117,
          25.237685210773485,
          20.967475692949943,
          5.036539861434353,
          -19.075259311548134,
          14.339032368741218,
          17.384239731858223,
          31.03661656650838,
          15.595316569132887,
          23.258859699229255,
          21.978100728756484,
          13.181113970908823,
          -0.5378874554353723,
          16.96009176911223,
          16.933318493887818,
          -1.4768922128320299,
          24.39235950742396,
          15.194475830417987,
          30.333715760682054,
          25.684283085220912,
          24.327492821130196,
          48.61990540748817,
          24.794565330837507,
          24.334053333668507,
          19.9905794482585,
          28.075258097663394,
          34.28344132537338,
          30.187638804268435,
          38.46244287664959,
          37.34835207417576,
          21.519810772096424,
          51.03806077853758,
          41.03479192536845,
          42.062959736734655,
          42.370361407600214,
          44.174765381351136,
          31.90973743657049,
          24.80833767723487,
          40.6250895555506,
          40.1415825701225
         ],
         "yaxis": "y"
        }
       ],
       "layout": {
        "legend": {
         "title": {
          "text": "agent"
         },
         "tracegroupgap": 0
        },
        "template": {
         "data": {
          "bar": [
           {
            "error_x": {
             "color": "#2a3f5f"
            },
            "error_y": {
             "color": "#2a3f5f"
            },
            "marker": {
             "line": {
              "color": "#E5ECF6",
              "width": 0.5
             },
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "bar"
           }
          ],
          "barpolar": [
           {
            "marker": {
             "line": {
              "color": "#E5ECF6",
              "width": 0.5
             },
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "barpolar"
           }
          ],
          "carpet": [
           {
            "aaxis": {
             "endlinecolor": "#2a3f5f",
             "gridcolor": "white",
             "linecolor": "white",
             "minorgridcolor": "white",
             "startlinecolor": "#2a3f5f"
            },
            "baxis": {
             "endlinecolor": "#2a3f5f",
             "gridcolor": "white",
             "linecolor": "white",
             "minorgridcolor": "white",
             "startlinecolor": "#2a3f5f"
            },
            "type": "carpet"
           }
          ],
          "choropleth": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "choropleth"
           }
          ],
          "contour": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "contour"
           }
          ],
          "contourcarpet": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "contourcarpet"
           }
          ],
          "heatmap": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "heatmap"
           }
          ],
          "heatmapgl": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "heatmapgl"
           }
          ],
          "histogram": [
           {
            "marker": {
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "histogram"
           }
          ],
          "histogram2d": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "histogram2d"
           }
          ],
          "histogram2dcontour": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "histogram2dcontour"
           }
          ],
          "mesh3d": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "mesh3d"
           }
          ],
          "parcoords": [
           {
            "line": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "parcoords"
           }
          ],
          "pie": [
           {
            "automargin": true,
            "type": "pie"
           }
          ],
          "scatter": [
           {
            "fillpattern": {
             "fillmode": "overlay",
             "size": 10,
             "solidity": 0.2
            },
            "type": "scatter"
           }
          ],
          "scatter3d": [
           {
            "line": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatter3d"
           }
          ],
          "scattercarpet": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattercarpet"
           }
          ],
          "scattergeo": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattergeo"
           }
          ],
          "scattergl": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattergl"
           }
          ],
          "scattermapbox": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattermapbox"
           }
          ],
          "scatterpolar": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterpolar"
           }
          ],
          "scatterpolargl": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterpolargl"
           }
          ],
          "scatterternary": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterternary"
           }
          ],
          "surface": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "surface"
           }
          ],
          "table": [
           {
            "cells": {
             "fill": {
              "color": "#EBF0F8"
             },
             "line": {
              "color": "white"
             }
            },
            "header": {
             "fill": {
              "color": "#C8D4E3"
             },
             "line": {
              "color": "white"
             }
            },
            "type": "table"
           }
          ]
         },
         "layout": {
          "annotationdefaults": {
           "arrowcolor": "#2a3f5f",
           "arrowhead": 0,
           "arrowwidth": 1
          },
          "autotypenumbers": "strict",
          "coloraxis": {
           "colorbar": {
            "outlinewidth": 0,
            "ticks": ""
           }
          },
          "colorscale": {
           "diverging": [
            [
             0,
             "#8e0152"
            ],
            [
             0.1,
             "#c51b7d"
            ],
            [
             0.2,
             "#de77ae"
            ],
            [
             0.3,
             "#f1b6da"
            ],
            [
             0.4,
             "#fde0ef"
            ],
            [
             0.5,
             "#f7f7f7"
            ],
            [
             0.6,
             "#e6f5d0"
            ],
            [
             0.7,
             "#b8e186"
            ],
            [
             0.8,
             "#7fbc41"
            ],
            [
             0.9,
             "#4d9221"
            ],
            [
             1,
             "#276419"
            ]
           ],
           "sequential": [
            [
             0,
             "#0d0887"
            ],
            [
             0.1111111111111111,
             "#46039f"
            ],
            [
             0.2222222222222222,
             "#7201a8"
            ],
            [
             0.3333333333333333,
             "#9c179e"
            ],
            [
             0.4444444444444444,
             "#bd3786"
            ],
            [
             0.5555555555555556,
             "#d8576b"
            ],
            [
             0.6666666666666666,
             "#ed7953"
            ],
            [
             0.7777777777777778,
             "#fb9f3a"
            ],
            [
             0.8888888888888888,
             "#fdca26"
            ],
            [
             1,
             "#f0f921"
            ]
           ],
           "sequentialminus": [
            [
             0,
             "#0d0887"
            ],
            [
             0.1111111111111111,
             "#46039f"
            ],
            [
             0.2222222222222222,
             "#7201a8"
            ],
            [
             0.3333333333333333,
             "#9c179e"
            ],
            [
             0.4444444444444444,
             "#bd3786"
            ],
            [
             0.5555555555555556,
             "#d8576b"
            ],
            [
             0.6666666666666666,
             "#ed7953"
            ],
            [
             0.7777777777777778,
             "#fb9f3a"
            ],
            [
             0.8888888888888888,
             "#fdca26"
            ],
            [
             1,
             "#f0f921"
            ]
           ]
          },
          "colorway": [
           "#636efa",
           "#EF553B",
           "#00cc96",
           "#ab63fa",
           "#FFA15A",
           "#19d3f3",
           "#FF6692",
           "#B6E880",
           "#FF97FF",
           "#FECB52"
          ],
          "font": {
           "color": "#2a3f5f"
          },
          "geo": {
           "bgcolor": "white",
           "lakecolor": "white",
           "landcolor": "#E5ECF6",
           "showlakes": true,
           "showland": true,
           "subunitcolor": "white"
          },
          "hoverlabel": {
           "align": "left"
          },
          "hovermode": "closest",
          "mapbox": {
           "style": "light"
          },
          "paper_bgcolor": "white",
          "plot_bgcolor": "#E5ECF6",
          "polar": {
           "angularaxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           },
           "bgcolor": "#E5ECF6",
           "radialaxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           }
          },
          "scene": {
           "xaxis": {
            "backgroundcolor": "#E5ECF6",
            "gridcolor": "white",
            "gridwidth": 2,
            "linecolor": "white",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "white"
           },
           "yaxis": {
            "backgroundcolor": "#E5ECF6",
            "gridcolor": "white",
            "gridwidth": 2,
            "linecolor": "white",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "white"
           },
           "zaxis": {
            "backgroundcolor": "#E5ECF6",
            "gridcolor": "white",
            "gridwidth": 2,
            "linecolor": "white",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "white"
           }
          },
          "shapedefaults": {
           "line": {
            "color": "#2a3f5f"
           }
          },
          "ternary": {
           "aaxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           },
           "baxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           },
           "bgcolor": "#E5ECF6",
           "caxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           }
          },
          "title": {
           "x": 0.05
          },
          "xaxis": {
           "automargin": true,
           "gridcolor": "white",
           "linecolor": "white",
           "ticks": "",
           "title": {
            "standoff": 15
           },
           "zerolinecolor": "white",
           "zerolinewidth": 2
          },
          "yaxis": {
           "automargin": true,
           "gridcolor": "white",
           "linecolor": "white",
           "ticks": "",
           "title": {
            "standoff": 15
           },
           "zerolinecolor": "white",
           "zerolinewidth": 2
          }
         }
        },
        "title": {
         "text": "300 epoch, batch=100, q=0.75"
        },
        "xaxis": {
         "anchor": "y",
         "domain": [
          0,
          1
         ],
         "title": {
          "text": "epoch"
         }
        },
        "yaxis": {
         "anchor": "x",
         "domain": [
          0,
          1
         ],
         "title": {
          "text": "reward"
         }
        }
       }
      }
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "df = pd.DataFrame.from_records(total_rewards)\n",
    "px.line(df, x='epoch', y='reward', color='agent', title='300 epoch, batch=100, q=0.75')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "По результатам обучения трех нейросетей можно сделать вывод, что сеть с меньшим количество слоев достигла своего локлаьго максимума на уровне 220-230. При этом, на удивление, сеть с 256 нейронами за 300 эпох не смогла превзойти сеть с 16 нейронами."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Для дальнейшего тюнинга за основу возьмем сеть с 64 нейронами, как лучшую с точки зрения времени/награды"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Попробуем уменьшить Q, чтобы сеть получала больше данных"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_model_total_rewards = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0: mean_reward=-190.69847243580236\n",
      "1: mean_reward=-164.15375744393245\n",
      "2: mean_reward=-171.13098045184842\n",
      "3: mean_reward=-147.66547248727593\n",
      "4: mean_reward=-145.85726182513505\n",
      "5: mean_reward=-149.20327303411204\n",
      "6: mean_reward=-157.7072770682559\n",
      "7: mean_reward=-132.72246200873684\n",
      "8: mean_reward=-128.6978596180105\n",
      "9: mean_reward=-135.33033186089975\n",
      "10: mean_reward=-121.61857293351731\n",
      "11: mean_reward=-118.29999067666137\n",
      "12: mean_reward=-109.79905275862797\n",
      "13: mean_reward=-107.16748576709023\n",
      "14: mean_reward=-110.35832213001538\n",
      "15: mean_reward=-110.05793000768037\n",
      "16: mean_reward=-127.31265609265348\n",
      "17: mean_reward=-111.7955191548696\n",
      "18: mean_reward=-108.45226401971851\n",
      "19: mean_reward=-102.77959005900433\n",
      "20: mean_reward=-99.50226583202286\n",
      "21: mean_reward=-98.42118025915117\n",
      "22: mean_reward=-94.90254835581877\n",
      "23: mean_reward=-93.24955228503106\n",
      "24: mean_reward=-92.87116415356209\n",
      "25: mean_reward=-95.44743477539889\n",
      "26: mean_reward=-76.89444213425851\n",
      "27: mean_reward=-85.76053289527222\n",
      "28: mean_reward=-90.59718021151821\n",
      "29: mean_reward=-77.67517630736852\n",
      "30: mean_reward=-68.73584135639527\n",
      "31: mean_reward=-73.01016244006874\n",
      "32: mean_reward=-78.41271498204055\n",
      "33: mean_reward=-74.05724240758175\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32mg:\\PycharmProjects\\DRL\\practice2\\Shastin_practice2_1.ipynb Cell 20\u001b[0m line \u001b[0;36m5\n\u001b[0;32m      <a href='vscode-notebook-cell:/g%3A/PycharmProjects/DRL/practice2/Shastin_practice2_1.ipynb#X45sZmlsZQ%3D%3D?line=1'>2</a>\u001b[0m agent \u001b[39m=\u001b[39m CEM(state_dim, action_n, hidden\u001b[39m=\u001b[39m\u001b[39m64\u001b[39m, lr\u001b[39m=\u001b[39mlr)\n\u001b[0;32m      <a href='vscode-notebook-cell:/g%3A/PycharmProjects/DRL/practice2/Shastin_practice2_1.ipynb#X45sZmlsZQ%3D%3D?line=3'>4</a>\u001b[0m \u001b[39mfor\u001b[39;00m i \u001b[39min\u001b[39;00m \u001b[39mrange\u001b[39m(MAX_ITER):\n\u001b[1;32m----> <a href='vscode-notebook-cell:/g%3A/PycharmProjects/DRL/practice2/Shastin_practice2_1.ipynb#X45sZmlsZQ%3D%3D?line=4'>5</a>\u001b[0m     batch_states, batch_actions, batch_rewards \u001b[39m=\u001b[39m generate_batch(env, agent, BATCH_SIZE, TRAJECTORY_LEN)\n\u001b[0;32m      <a href='vscode-notebook-cell:/g%3A/PycharmProjects/DRL/practice2/Shastin_practice2_1.ipynb#X45sZmlsZQ%3D%3D?line=5'>6</a>\u001b[0m     elite_states, elite_actions \u001b[39m=\u001b[39m get_elite_states(batch_states, batch_actions, batch_rewards, Q)\n\u001b[0;32m      <a href='vscode-notebook-cell:/g%3A/PycharmProjects/DRL/practice2/Shastin_practice2_1.ipynb#X45sZmlsZQ%3D%3D?line=7'>8</a>\u001b[0m     mean_reward \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39mmean(batch_rewards)\n",
      "\u001b[1;32mg:\\PycharmProjects\\DRL\\practice2\\Shastin_practice2_1.ipynb Cell 20\u001b[0m line \u001b[0;36m1\n\u001b[0;32m      <a href='vscode-notebook-cell:/g%3A/PycharmProjects/DRL/practice2/Shastin_practice2_1.ipynb#X45sZmlsZQ%3D%3D?line=7'>8</a>\u001b[0m state \u001b[39m=\u001b[39m env\u001b[39m.\u001b[39mreset()\n\u001b[0;32m      <a href='vscode-notebook-cell:/g%3A/PycharmProjects/DRL/practice2/Shastin_practice2_1.ipynb#X45sZmlsZQ%3D%3D?line=8'>9</a>\u001b[0m \u001b[39mfor\u001b[39;00m _ \u001b[39min\u001b[39;00m \u001b[39mrange\u001b[39m(trajectory_len):\n\u001b[1;32m---> <a href='vscode-notebook-cell:/g%3A/PycharmProjects/DRL/practice2/Shastin_practice2_1.ipynb#X45sZmlsZQ%3D%3D?line=9'>10</a>\u001b[0m     action \u001b[39m=\u001b[39m agent\u001b[39m.\u001b[39;49mget_action(state)\n\u001b[0;32m     <a href='vscode-notebook-cell:/g%3A/PycharmProjects/DRL/practice2/Shastin_practice2_1.ipynb#X45sZmlsZQ%3D%3D?line=10'>11</a>\u001b[0m     new_state, reward, done, _ \u001b[39m=\u001b[39m env\u001b[39m.\u001b[39mstep(action)\n\u001b[0;32m     <a href='vscode-notebook-cell:/g%3A/PycharmProjects/DRL/practice2/Shastin_practice2_1.ipynb#X45sZmlsZQ%3D%3D?line=11'>12</a>\u001b[0m     states\u001b[39m.\u001b[39mappend(state)\n",
      "\u001b[1;32mg:\\PycharmProjects\\DRL\\practice2\\Shastin_practice2_1.ipynb Cell 20\u001b[0m line \u001b[0;36m2\n\u001b[0;32m     <a href='vscode-notebook-cell:/g%3A/PycharmProjects/DRL/practice2/Shastin_practice2_1.ipynb#X45sZmlsZQ%3D%3D?line=21'>22</a>\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mget_action\u001b[39m(\u001b[39mself\u001b[39m, state):\n\u001b[0;32m     <a href='vscode-notebook-cell:/g%3A/PycharmProjects/DRL/practice2/Shastin_practice2_1.ipynb#X45sZmlsZQ%3D%3D?line=22'>23</a>\u001b[0m     state \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39mFloatTensor(state)\n\u001b[1;32m---> <a href='vscode-notebook-cell:/g%3A/PycharmProjects/DRL/practice2/Shastin_practice2_1.ipynb#X45sZmlsZQ%3D%3D?line=23'>24</a>\u001b[0m     logits \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mforward(state)\n\u001b[0;32m     <a href='vscode-notebook-cell:/g%3A/PycharmProjects/DRL/practice2/Shastin_practice2_1.ipynb#X45sZmlsZQ%3D%3D?line=24'>25</a>\u001b[0m     action_prob \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39msoftmax(logits)\u001b[39m.\u001b[39mdetach()\u001b[39m.\u001b[39mnumpy()\n\u001b[0;32m     <a href='vscode-notebook-cell:/g%3A/PycharmProjects/DRL/practice2/Shastin_practice2_1.ipynb#X45sZmlsZQ%3D%3D?line=26'>27</a>\u001b[0m     noise \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39mones(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39maction_n) \u001b[39m/\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39maction_n\n",
      "\u001b[1;32mg:\\PycharmProjects\\DRL\\practice2\\Shastin_practice2_1.ipynb Cell 20\u001b[0m line \u001b[0;36m2\n\u001b[0;32m     <a href='vscode-notebook-cell:/g%3A/PycharmProjects/DRL/practice2/Shastin_practice2_1.ipynb#X45sZmlsZQ%3D%3D?line=18'>19</a>\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mforward\u001b[39m(\u001b[39mself\u001b[39m, _input):\n\u001b[1;32m---> <a href='vscode-notebook-cell:/g%3A/PycharmProjects/DRL/practice2/Shastin_practice2_1.ipynb#X45sZmlsZQ%3D%3D?line=19'>20</a>\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mnetwork(_input)\n",
      "File \u001b[1;32mg:\\PycharmProjects\\DRL\\env\\lib\\site-packages\\torch\\nn\\modules\\module.py:1518\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1516\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_compiled_call_impl(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)  \u001b[39m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1517\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m-> 1518\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_call_impl(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mg:\\PycharmProjects\\DRL\\env\\lib\\site-packages\\torch\\nn\\modules\\module.py:1527\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1522\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1523\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1524\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_pre_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1525\u001b[0m         \u001b[39mor\u001b[39;00m _global_backward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1526\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1527\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m   1529\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m   1530\u001b[0m     result \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n",
      "File \u001b[1;32mg:\\PycharmProjects\\DRL\\env\\lib\\site-packages\\torch\\nn\\modules\\container.py:215\u001b[0m, in \u001b[0;36mSequential.forward\u001b[1;34m(self, input)\u001b[0m\n\u001b[0;32m    213\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mforward\u001b[39m(\u001b[39mself\u001b[39m, \u001b[39minput\u001b[39m):\n\u001b[0;32m    214\u001b[0m     \u001b[39mfor\u001b[39;00m module \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m:\n\u001b[1;32m--> 215\u001b[0m         \u001b[39minput\u001b[39m \u001b[39m=\u001b[39m module(\u001b[39minput\u001b[39;49m)\n\u001b[0;32m    216\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39minput\u001b[39m\n",
      "File \u001b[1;32mg:\\PycharmProjects\\DRL\\env\\lib\\site-packages\\torch\\nn\\modules\\module.py:1518\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1516\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_compiled_call_impl(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)  \u001b[39m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1517\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m-> 1518\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_call_impl(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mg:\\PycharmProjects\\DRL\\env\\lib\\site-packages\\torch\\nn\\modules\\module.py:1527\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1522\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1523\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1524\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_pre_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1525\u001b[0m         \u001b[39mor\u001b[39;00m _global_backward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1526\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1527\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m   1529\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m   1530\u001b[0m     result \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n",
      "File \u001b[1;32mg:\\PycharmProjects\\DRL\\env\\lib\\site-packages\\torch\\nn\\modules\\linear.py:114\u001b[0m, in \u001b[0;36mLinear.forward\u001b[1;34m(self, input)\u001b[0m\n\u001b[0;32m    113\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mforward\u001b[39m(\u001b[39mself\u001b[39m, \u001b[39minput\u001b[39m: Tensor) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m Tensor:\n\u001b[1;32m--> 114\u001b[0m     \u001b[39mreturn\u001b[39;00m F\u001b[39m.\u001b[39;49mlinear(\u001b[39minput\u001b[39;49m, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mweight, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mbias)\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "Q = 0.6\n",
    "agent = CEM(state_dim, action_n, hidden=64, lr=lr)\n",
    "\n",
    "for i in range(MAX_ITER):\n",
    "    batch_states, batch_actions, batch_rewards = generate_batch(env, agent, BATCH_SIZE, TRAJECTORY_LEN)\n",
    "    elite_states, elite_actions = get_elite_states(batch_states, batch_actions, batch_rewards, Q)\n",
    "    \n",
    "    mean_reward = np.mean(batch_rewards)\n",
    "    best_model_total_rewards.append({'agent': 'one_layer_64', 'epoch': i, 'q': Q, 'reward': mean_reward})\n",
    "    agent.update_policy(elite_states, elite_actions)\n",
    "    print(f'{i}: mean_reward={mean_reward}')\n",
    "\n",
    "time_end = time.time()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
